{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from patchify import patchify\n",
    "import tifffile as tiff\n",
    "import os\n",
    "from PIL import Image\n",
    "from math import floor\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_patches(\n",
    "    dataset_dir,\n",
    "    save_dir,\n",
    "    patch_size=224,\n",
    "):\n",
    "    original_sample_names = os.listdir(dataset_dir)\n",
    "\n",
    "    for name in original_sample_names:\n",
    "        sample_path = os.path.join(dataset_dir, name)\n",
    "        image = tiff.imread(sample_path, key=0)\n",
    "        print(image.shape)\n",
    "        h, w, c = image.shape\n",
    "\n",
    "        if h >= patch_size and w >= patch_size:\n",
    "            h_new = floor(h / patch_size) * patch_size\n",
    "            w_new = floor(w / patch_size) * patch_size\n",
    "            image = image[:h_new, :w_new, :]\n",
    "            print(image.shape)\n",
    "\n",
    "            patches_imgs = patchify(image, (224, 224, 3), step=224)\n",
    "            print(\"N patches \", patches_imgs.shape)\n",
    "\n",
    "            for i in range(len(patches_imgs)):\n",
    "                for j in range(len(patches_imgs[i])):\n",
    "                    im = Image.fromarray(patches_imgs[i][j][0])\n",
    "                    save_path = os.path.join(save_dir, f\"{name.split('.')[0]}_{i}_{j}.jpeg\")\n",
    "                    im.save(save_path)\n",
    "        else:\n",
    "            print(\"Skipping image: patch size too big!\")\n",
    "\n",
    "    return os.listdir(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide dataset images into batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Carefull of a bias in the data**: crow traps are generally placed in the center of the image! After generating patches, the crow trpas will (almost) always placed at the top left corner of the patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(508, 430, 4)\n",
      "(448, 224, 4)\n",
      "N patches  (2, 1, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(508, 430, 4)\n",
      "(448, 224, 4)\n",
      "N patches  (2, 1, 1, 224, 224, 3)\n",
      "(508, 430, 4)\n",
      "(448, 224, 4)\n",
      "N patches  (2, 1, 1, 224, 224, 3)\n",
      "(508, 430, 4)\n",
      "(448, 224, 4)\n",
      "N patches  (2, 1, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(508, 367, 4)\n",
      "(448, 224, 4)\n",
      "N patches  (2, 1, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 861, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n",
      "(1016, 860, 4)\n",
      "(896, 672, 4)\n",
      "N patches  (4, 3, 1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "pathes_names = make_patches(\n",
    "    dataset_dir=\"Datasets/backup/Crow_traps_Subset\",\n",
    "    save_dir=\"Datasets/Crow_traps_splits/background\",\n",
    "    patch_size=224,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total N pathces:  526\n"
     ]
    }
   ],
   "source": [
    "print(\"Total N pathces: \", len(pathes_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, manually select patches that contain crow traps and move it to the \"crow_trap\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Script for renaming and repositioning files\n",
    "'''\n",
    "\n",
    "class_dir = \"Datasets/Crow_classify/background_tiff\"\n",
    "output_dir = \"Datasets/Crow_classify/background\"\n",
    "\n",
    "samples = os.listdir(class_dir)\n",
    "\n",
    "for sample in samples:\n",
    "    dot_splits = sample.split(\".\")\n",
    "    name = dot_splits[0]\n",
    "    under_splits = dot_splits[1].split(\"_\")\n",
    "    position = under_splits[1]+\"_\"+under_splits[2]\n",
    "    file_name = name+\"_\"+position\n",
    "\n",
    "    sample_path = os.path.join(class_dir, sample)\n",
    "    save_path = os.path.join(output_dir, file_name+\".jpeg\")\n",
    "\n",
    "    shutil.copyfile(sample_path, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample list:  45\n",
      "36 9\n",
      "Sample list:  481\n",
      "384 97\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def make_split(class_name, dataset_dir=\"Datasets/Crow_classify\", split_p=0.2):\n",
    "    class_dir = os.path.join(dataset_dir, class_name)\n",
    "    samples_list = os.listdir(class_dir)\n",
    "\n",
    "    print(\"Sample list: \", len(samples_list))\n",
    "\n",
    "    samples_train, samples_test = train_test_split(samples_list, test_size=split_p, random_state=42)\n",
    "\n",
    "    print(len(samples_train), len(samples_test))\n",
    "\n",
    "    train_dir = os.path.join(dataset_dir, \"train\", class_name)\n",
    "    test_dir = os.path.join(dataset_dir, \"test\", class_name)\n",
    "\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.makedirs(test_dir)\n",
    "\n",
    "    for sample in samples_test:\n",
    "        sample_path = os.path.join(class_dir, sample)\n",
    "        save_path = os.path.join(test_dir, sample)\n",
    "\n",
    "        shutil.copyfile(sample_path, save_path)\n",
    "\n",
    "    for sample in samples_train:\n",
    "        sample_path = os.path.join(class_dir, sample)\n",
    "        save_path = os.path.join(train_dir, sample)\n",
    "\n",
    "        shutil.copyfile(sample_path, save_path)\n",
    "\n",
    "make_split(\"crow_trap\", dataset_dir=\"Datasets/Crow_classify\", split_p=0.2)\n",
    "make_split(\"background\", dataset_dir=\"Datasets/Crow_classify\", split_p=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train split can be used to generate augmented data and reduce imbalance in the dataset.\n",
    "\n",
    "- **crow_trap generation**: traps are manually masked out and then placed into background images\n",
    "- **general augmentation**: background/crow_trap images can be transformed and distorted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crow trap generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103138_0_0_14.png\n",
      "103638_2_1_3.png\n",
      "101339_0_2_13.png\n",
      "99911_3_1_1.png\n",
      "102563_1_0_15.png\n",
      "104201_1_1_5.png\n",
      "103303_0_0_2.png\n",
      "100631_1_2_11.png\n",
      "100631_0_1_18.png\n",
      "101548_3_0_16.png\n",
      "101679_2_0_17.png\n",
      "102521_1_1_17.png\n",
      "102523_1_0_18.png\n",
      "101164_0_0_3.png\n",
      "103849_1_0_11.png\n",
      "101442_0_1_18.png\n",
      "101559_1_1_3.png\n",
      "101550_3_0_2.png\n",
      "102523_3_2_4.png\n",
      "101550_1_2_11.png\n",
      "103638_2_0_16.png\n",
      "101559_2_0_1.png\n",
      "103303_1_2_4.png\n",
      "103439_1_1_17.png\n",
      "104268_2_0_3.png\n",
      "101125_1_1_17.png\n",
      "102520_3_1_5.png\n",
      "101559_0_1_7.png\n",
      "101520_2_0_17.png\n",
      "101517_1_0_13.png\n",
      "102522_2_0_1.png\n",
      "99495_3_2_16.png\n",
      "104272_2_0_17.png\n",
      "102521_0_1_8.png\n",
      "101343_1_0_5.png\n",
      "102598_0_2_2.png\n",
      "99911_2_2_1.png\n",
      "101569_1_0_9.png\n",
      "101679_3_0_16.png\n",
      "101569_2_0_17.png\n",
      "104268_3_1_6.png\n",
      "102522_1_2_4.png\n",
      "101546_0_0_14.png\n",
      "101569_0_2_17.png\n",
      "99911_0_0_1.png\n",
      "102237_2_2_3.png\n",
      "101559_2_2_3.png\n",
      "102522_1_1_11.png\n",
      "100615_2_2_4.png\n",
      "102601_2_2_13.png\n",
      "100459_0_2_7.png\n",
      "101520_0_2_13.png\n",
      "104272_3_1_1.png\n",
      "101125_1_2_6.png\n",
      "101123_1_2_16.png\n",
      "100631_3_1_10.png\n",
      "101343_1_2_8.png\n",
      "104270_0_1_13.png\n",
      "102522_0_1_13.png\n",
      "104269_3_1_8.png\n",
      "102601_1_0_1.png\n",
      "101517_3_0_14.png\n",
      "101559_1_0_16.png\n",
      "102563_1_2_5.png\n",
      "102563_3_1_1.png\n",
      "103439_3_2_7.png\n",
      "104008_3_2_2.png\n",
      "103519_0_0_6.png\n",
      "104201_1_2_4.png\n",
      "103138_3_2_3.png\n",
      "104357_0_0_12.png\n",
      "101679_3_2_9.png\n",
      "104357_2_2_5.png\n",
      "103710_2_0_14.png\n",
      "101343_2_2_11.png\n",
      "102522_0_2_16.png\n",
      "104270_1_1_2.png\n",
      "101559_0_2_1.png\n",
      "101550_0_0_15.png\n",
      "102601_3_2_17.png\n",
      "101123_0_1_11.png\n",
      "101548_2_2_10.png\n",
      "101569_1_1_12.png\n",
      "101509_3_2_13.png\n",
      "102598_0_0_17.png\n",
      "101559_3_2_11.png\n",
      "103303_0_2_2.png\n",
      "102521_2_0_9.png\n",
      "102521_0_2_7.png\n",
      "101559_3_0_6.png\n",
      "104269_2_2_6.png\n",
      "100615_0_1_9.png\n",
      "102601_1_1_18.png\n",
      "104201_0_1_11.png\n",
      "101339_2_0_18.png\n",
      "101520_0_1_6.png\n",
      "99245_1_0_10.png\n",
      "100615_1_1_3.png\n",
      "104272_0_1_13.png\n",
      "101546_3_2_8.png\n",
      "101509_0_1_5.png\n",
      "103439_0_1_17.png\n",
      "102520_0_0_13.png\n",
      "101546_2_2_2.png\n",
      "101569_3_1_13.png\n",
      "104008_0_1_1.png\n",
      "104269_1_2_13.png\n",
      "101517_2_0_7.png\n",
      "101123_1_1_18.png\n",
      "99495_0_0_11.png\n",
      "101125_3_1_13.png\n",
      "101679_0_1_13.png\n",
      "101546_3_0_3.png\n",
      "101442_3_0_2.png\n",
      "104270_1_2_18.png\n",
      "101509_2_0_1.png\n",
      "101442_1_0_15.png\n",
      "102237_1_1_9.png\n",
      "103638_2_2_17.png\n",
      "104272_3_0_6.png\n",
      "100459_2_2_5.png\n",
      "103849_1_2_3.png\n",
      "99495_1_0_16.png\n",
      "103710_0_2_13.png\n",
      "104269_0_1_12.png\n",
      "102520_1_1_11.png\n",
      "103138_0_1_2.png\n",
      "101550_3_2_8.png\n",
      "103519_1_1_7.png\n",
      "101548_0_1_5.png\n",
      "101520_1_1_16.png\n",
      "102523_3_1_7.png\n",
      "103519_1_0_17.png\n",
      "103710_3_0_7.png\n",
      "100459_0_0_9.png\n",
      "100631_0_2_12.png\n",
      "103519_1_2_9.png\n",
      "104268_3_2_8.png\n",
      "99911_1_2_14.png\n",
      "102563_3_0_5.png\n",
      "101517_1_2_7.png\n",
      "102523_2_2_2.png\n",
      "101517_0_2_11.png\n",
      "102601_0_1_9.png\n",
      "103638_0_0_1.png\n",
      "100615_3_0_13.png\n",
      "102522_2_2_4.png\n",
      "101509_3_1_10.png\n",
      "104272_3_2_4.png\n",
      "103849_2_2_16.png\n",
      "102563_2_1_3.png\n",
      "102520_0_1_16.png\n",
      "103138_2_0_13.png\n",
      "101123_3_1_15.png\n",
      "104270_3_2_7.png\n",
      "102523_0_0_9.png\n",
      "102601_0_2_8.png\n",
      "104268_0_0_16.png\n",
      "102601_2_0_8.png\n",
      "104201_3_0_17.png\n",
      "100331_3_0_8.png\n",
      "101550_2_2_4.png\n",
      "102521_3_0_15.png\n",
      "104201_2_2_9.png\n",
      "104268_2_2_13.png\n",
      "99911_0_1_6.png\n",
      "101343_0_0_11.png\n",
      "103303_3_2_10.png\n",
      "104269_1_0_13.png\n",
      "103519_2_2_11.png\n",
      "101442_1_1_9.png\n",
      "104268_1_1_18.png\n",
      "102237_3_1_18.png\n",
      "103138_3_0_17.png\n",
      "101679_0_0_15.png\n",
      "99245_0_0_4.png\n",
      "100331_0_0_16.png\n",
      "101509_2_2_2.png\n",
      "102521_2_2_3.png\n",
      "104272_0_0_8.png\n",
      "101520_3_0_15.png\n",
      "101517_0_1_12.png\n",
      "102520_3_2_8.png\n",
      "102523_0_1_3.png\n",
      "101343_3_2_14.png\n",
      "101569_1_2_10.png\n",
      "103710_1_1_7.png\n",
      "103710_0_1_6.png\n",
      "103138_0_2_1.png\n",
      "104270_3_0_9.png\n",
      "103303_1_1_18.png\n",
      "102521_1_0_17.png\n",
      "100459_3_2_2.png\n",
      "100459_0_1_8.png\n",
      "101509_1_2_13.png\n",
      "104008_3_0_14.png\n",
      "102520_1_0_7.png\n",
      "104272_1_0_17.png\n",
      "99495_0_1_11.png\n",
      "104008_1_1_8.png\n",
      "104269_0_0_3.png\n",
      "101679_3_1_1.png\n",
      "104272_1_2_2.png\n",
      "101339_3_2_7.png\n",
      "102563_0_1_8.png\n",
      "102520_1_2_6.png\n",
      "103439_2_2_13.png\n",
      "102237_2_0_16.png\n",
      "104008_1_2_15.png\n",
      "101123_0_2_6.png\n",
      "102598_1_2_13.png\n",
      "103138_1_1_5.png\n",
      "101548_1_0_9.png\n",
      "99495_1_1_7.png\n",
      "102563_2_0_14.png\n",
      "100459_3_0_18.png\n",
      "104357_3_1_8.png\n",
      "104268_0_1_16.png\n",
      "102237_0_0_12.png\n",
      "100980_1_1_16.png\n",
      "101339_2_2_14.png\n",
      "99911_1_0_7.png\n",
      "101520_3_2_5.png\n",
      "103138_2_2_13.png\n",
      "103138_1_0_10.png\n",
      "104201_0_0_12.png\n",
      "100331_3_2_15.png\n",
      "99495_0_2_5.png\n",
      "102521_3_1_4.png\n",
      "102237_0_2_16.png\n",
      "103638_3_1_12.png\n",
      "101569_3_2_4.png\n",
      "104270_2_2_17.png\n",
      "101548_0_0_9.png\n",
      "101123_3_0_2.png\n",
      "103439_1_0_7.png\n",
      "101442_0_2_14.png\n",
      "104357_0_2_11.png\n",
      "100331_1_0_1.png\n",
      "102237_1_2_11.png\n",
      "101548_1_2_6.png\n",
      "104269_3_2_5.png\n",
      "102523_0_2_1.png\n",
      "102522_3_0_10.png\n",
      "104270_3_1_11.png\n",
      "101550_0_1_7.png\n",
      "102563_0_2_6.png\n",
      "100980_1_0_6.png\n",
      "101517_3_2_17.png\n",
      "103303_1_0_1.png\n",
      "101548_3_2_16.png\n",
      "99911_3_0_5.png\n",
      "103638_0_2_17.png\n",
      "102520_3_0_12.png\n",
      "101517_1_1_13.png\n",
      "103519_3_2_4.png\n",
      "104008_3_1_7.png\n",
      "101125_3_0_16.png\n",
      "101164_1_0_5.png\n",
      "103710_3_1_17.png\n",
      "101550_0_2_7.png\n",
      "100980_1_2_2.png\n",
      "101546_0_1_1.png\n",
      "102521_3_2_7.png\n",
      "104269_3_0_15.png\n",
      "100631_2_2_7.png\n",
      "99911_1_1_8.png\n",
      "104269_2_0_7.png\n",
      "103638_1_1_5.png\n",
      "101548_3_1_10.png\n",
      "104201_0_2_13.png\n",
      "102237_3_0_7.png\n",
      "102523_1_1_9.png\n",
      "100631_3_0_6.png\n",
      "103849_2_0_4.png\n",
      "104008_0_2_6.png\n",
      "101520_1_2_16.png\n",
      "101550_1_0_8.png\n",
      "101517_3_1_12.png\n",
      "102523_1_2_3.png\n",
      "99911_0_2_17.png\n",
      "102598_2_2_8.png\n",
      "100631_0_0_10.png\n",
      "104201_2_0_16.png\n",
      "101125_0_1_1.png\n",
      "103519_0_1_8.png\n",
      "104008_0_0_2.png\n",
      "104008_2_2_1.png\n",
      "103439_0_2_14.png\n",
      "103710_3_2_1.png\n",
      "100615_1_0_14.png\n",
      "99911_2_0_15.png\n",
      "100631_1_1_3.png\n",
      "104272_1_1_16.png\n",
      "100980_3_2_5.png\n",
      "101546_1_0_18.png\n",
      "102521_0_0_1.png\n",
      "103519_0_2_10.png\n",
      "100331_0_1_16.png\n",
      "102522_3_1_15.png\n",
      "101546_0_2_9.png\n",
      "103303_2_2_16.png\n",
      "103638_3_0_16.png\n",
      "102237_3_2_5.png\n",
      "103303_0_1_13.png\n",
      "102520_2_0_17.png\n",
      "99495_1_2_4.png\n",
      "101343_3_0_5.png\n"
     ]
    }
   ],
   "source": [
    "transform_p = 0.5\n",
    "back_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(transform_p),\n",
    "        transforms.RandomVerticalFlip(transform_p),\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.5, contrast=0.15, saturation=0.3, hue=0.3\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(transform_p),\n",
    "        transforms.RandomVerticalFlip(transform_p),\n",
    "        transforms.RandomRotation((0, 360)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "trap_dir = \"Datasets/backup/Only_traps\"\n",
    "back_dir = \"Datasets/Crow_classify/train/background\"\n",
    "save_dir = \"Datasets/Crow_classify/generated_traps\"\n",
    "\n",
    "# Proportion of background images to augment with crow traps\n",
    "split_p = 0.8\n",
    "\n",
    "_, samples_back = train_test_split(os.listdir(back_dir), test_size=split_p, random_state=42)\n",
    "samples_trap = os.listdir(trap_dir)\n",
    "\n",
    "for sample in samples_back:\n",
    "    back = Image.open(os.path.join(back_dir, sample))\n",
    "\n",
    "    sample_trap = random.choice(samples_trap)\n",
    "    trap = Image.open(os.path.join(trap_dir, sample_trap))\n",
    "\n",
    "    x = random.randint(24, 200)\n",
    "    y = random.randint(24, 200)\n",
    "\n",
    "    trap = test_transforms(trap)\n",
    "\n",
    "    back.paste(trap, (x, y), trap)\n",
    "    print(sample.split(\".\")[0] + \"_\" + sample_trap)\n",
    "    back = back_transforms(back)\n",
    "    back.save(os.path.join(save_dir, sample.split(\".\")[0] + \"_\" + sample_trap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### General augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101343_2_0_aug.jpeg\n",
      "103710_1_0_aug.jpeg\n",
      "103138_1_0_aug.jpeg\n",
      "104357_2_2_aug.jpeg\n",
      "101520_3_0_aug.jpeg\n",
      "102523_3_1_aug.jpeg\n",
      "104008_1_2_aug.jpeg\n",
      "101164_0_0_aug.jpeg\n",
      "102237_1_0_aug.jpeg\n",
      "103710_0_1_aug.jpeg\n",
      "101559_2_0_aug.jpeg\n",
      "99911_3_0_aug.jpeg\n",
      "103138_3_2_aug.jpeg\n",
      "101679_3_1_aug.jpeg\n",
      "104268_1_2_aug.jpeg\n",
      "103439_2_2_aug.jpeg\n",
      "99495_1_2_aug.jpeg\n",
      "104269_1_0_aug.jpeg\n",
      "102237_2_2_aug.jpeg\n",
      "101509_0_2_aug.jpeg\n",
      "100615_1_1_aug.jpeg\n",
      "101550_0_2_aug.jpeg\n",
      "103303_2_0_aug.jpeg\n",
      "99911_1_1_aug.jpeg\n",
      "101343_0_0_aug.jpeg\n",
      "101548_1_2_aug.jpeg\n",
      "104270_0_0_aug.jpeg\n",
      "104268_0_2_aug.jpeg\n",
      "103303_0_2_aug.jpeg\n",
      "101509_3_0_aug.jpeg\n",
      "104269_1_2_aug.jpeg\n",
      "101442_2_2_aug.jpeg\n",
      "100980_1_0_aug.jpeg\n",
      "102522_2_2_aug.jpeg\n",
      "102521_1_0_aug.jpeg\n",
      "101679_0_2_aug.jpeg\n",
      "104268_3_1_aug.jpeg\n",
      "101442_2_2_aug.jpeg\n",
      "102520_1_2_aug.jpeg\n",
      "101517_0_1_aug.jpeg\n",
      "104270_0_0_aug.jpeg\n",
      "100631_3_0_aug.jpeg\n",
      "104272_2_0_aug.jpeg\n",
      "102520_1_0_aug.jpeg\n",
      "103439_0_1_aug.jpeg\n",
      "101125_0_2_aug.jpeg\n",
      "102521_3_0_aug.jpeg\n",
      "100459_0_0_aug.jpeg\n",
      "100631_3_0_aug.jpeg\n",
      "104357_3_2_aug.jpeg\n",
      "103303_1_0_aug.jpeg\n",
      "104201_0_0_aug.jpeg\n",
      "101546_1_2_aug.jpeg\n",
      "102601_0_2_aug.jpeg\n",
      "100980_0_0_aug.jpeg\n",
      "102520_3_2_aug.jpeg\n",
      "102523_1_1_aug.jpeg\n",
      "104270_0_0_aug.jpeg\n",
      "103138_3_1_aug.jpeg\n",
      "101343_0_0_aug.jpeg\n",
      "100631_2_2_aug.jpeg\n",
      "102237_1_2_aug.jpeg\n",
      "104357_2_0_aug.jpeg\n",
      "101123_3_1_aug.jpeg\n",
      "101164_0_0_aug.jpeg\n",
      "101550_2_2_aug.jpeg\n",
      "102601_3_2_aug.jpeg\n",
      "103849_3_0_aug.jpeg\n",
      "103710_0_2_aug.jpeg\n",
      "103519_1_2_aug.jpeg\n",
      "99911_1_2_aug.jpeg\n",
      "101339_3_2_aug.jpeg\n",
      "101125_2_2_aug.jpeg\n",
      "102523_3_1_aug.jpeg\n",
      "102521_0_1_aug.jpeg\n",
      "101509_2_0_aug.jpeg\n",
      "103439_2_2_13_aug.jpeg\n",
      "99495_1_1_7_aug.jpeg\n",
      "101442_1_1_9_aug.jpeg\n",
      "103638_3_0_16_aug.jpeg\n",
      "101517_1_1_13_aug.jpeg\n",
      "102523_1_2_3_aug.jpeg\n",
      "103439_0_1_17_aug.jpeg\n",
      "101520_3_0_15_aug.jpeg\n",
      "102237_3_1_18_aug.jpeg\n",
      "100563_1_0_aug.jpeg\n",
      "102523_1_1_9_aug.jpeg\n",
      "101548_0_0_9_aug.jpeg\n",
      "104357_3_1_8_aug.jpeg\n",
      "101679_0_0_15_aug.jpeg\n",
      "99911_2_0_15_aug.jpeg\n",
      "104268_1_1_18_aug.jpeg\n",
      "99911_1_0_7_aug.jpeg\n",
      "99911_2_0_15_aug.jpeg\n",
      "101343_1_0_5_aug.jpeg\n",
      "101123_3_1_15_aug.jpeg\n",
      "101559_2_2_3_aug.jpeg\n",
      "103638_1_1_5_aug.jpeg\n",
      "104269_0_1_12_aug.jpeg\n",
      "101517_3_1_12_aug.jpeg\n",
      "101123_3_1_15_aug.jpeg\n",
      "102520_2_1_aug.jpeg\n",
      "104269_0_1_12_aug.jpeg\n",
      "103710_0_1_6_aug.jpeg\n",
      "104268_2_0_3_aug.jpeg\n",
      "102237_1_2_11_aug.jpeg\n",
      "103439_0_1_17_aug.jpeg\n",
      "102237_0_2_16_aug.jpeg\n",
      "103519_1_1_7_aug.jpeg\n",
      "100631_3_1_10_aug.jpeg\n",
      "103138_3_0_17_aug.jpeg\n",
      "103638_3_1_12_aug.jpeg\n",
      "104269_3_1_8_aug.jpeg\n",
      "101679_0_1_13_aug.jpeg\n",
      "101550_3_0_2_aug.jpeg\n",
      "104272_3_1_1_aug.jpeg\n",
      "102237_0_0_12_aug.jpeg\n",
      "100331_1_0_1_aug.jpeg\n",
      "100631_0_0_10_aug.jpeg\n",
      "104269_3_1_8_aug.jpeg\n",
      "104272_3_0_6_aug.jpeg\n",
      "99495_0_1_11_aug.jpeg\n",
      "102520_2_0_17_aug.jpeg\n",
      "104269_2_0_7_aug.jpeg\n",
      "102522_0_1_13_aug.jpeg\n",
      "103519_2_2_11_aug.jpeg\n",
      "104201_2_2_9_aug.jpeg\n",
      "102520_1_1_11_aug.jpeg\n",
      "102521_1_1_17_aug.jpeg\n",
      "101343_0_0_11_aug.jpeg\n",
      "102521_3_2_7_aug.jpeg\n",
      "102523_3_1_7_aug.jpeg\n",
      "99495_0_1_11_aug.jpeg\n",
      "99911_2_1_aug.jpeg\n",
      "103303_1_0_1_aug.jpeg\n",
      "101164_1_0_5_aug.jpeg\n",
      "104268_3_2_8_aug.jpeg\n",
      "102521_0_0_1_aug.jpeg\n",
      "103638_2_0_16_aug.jpeg\n",
      "101343_2_2_11_aug.jpeg\n",
      "104269_3_2_5_aug.jpeg\n",
      "100615_2_2_4_aug.jpeg\n",
      "101559_0_2_1_aug.jpeg\n",
      "101559_2_1_aug.jpeg\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms.autoaugment import AutoAugmentPolicy\n",
    "\n",
    "transform_p = 0.8\n",
    "\n",
    "def apply_general_augmentation(samples_dir, save_dir, p_to_generate = 0.65, auto_augment_policy = AutoAugmentPolicy.SVHN, replace=True):\n",
    "\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.RandomVerticalFlip(0.5),\n",
    "            transforms.AutoAugment(auto_augment_policy),\n",
    "            transforms.ColorJitter(\n",
    "                brightness=0.5, contrast=0.15, saturation=0.3, hue=0.3\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    samples_list = random.choices(\n",
    "        os.listdir(samples_dir), k=int(len(os.listdir(samples_dir)) * p_to_generate)\n",
    "    )\n",
    "\n",
    "    for sample in samples_list:\n",
    "\n",
    "        sample_img = Image.open(os.path.join(samples_dir, sample))\n",
    "        sample_img = transform(sample_img)\n",
    "        \n",
    "        sample_name = sample.split(\".\")[0] + \"_aug\" + \".jpeg\"\n",
    "        if replace:\n",
    "            sample_name = sample\n",
    "\n",
    "        print(sample_name)\n",
    "        sample_img.save(os.path.join(save_dir, sample_name))\n",
    "\n",
    "apply_general_augmentation(\"Datasets/Crow_classify/train/background\", \"Datasets/Crow_classify/train/background\", p_to_generate = 0.2, replace=False)\n",
    "apply_general_augmentation(\"Datasets/Crow_classify/train/crow_trap\", \"Datasets/Crow_classify/train/crow_trap\", p_to_generate = 0.2, replace=False)\n",
    "\n",
    "# apply_general_augmentation(\"Datasets/Crow_classify/train/background\", \"Datasets/Crow_classify/train/background\", p_to_generate = 0.2, replace=True)\n",
    "# apply_general_augmentation(\"Datasets/Crow_classify/train/crow_trap\", \"Datasets/Crow_classify/train/crow_trap\", p_to_generate = 0.2, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample list:  406\n",
      "345 61\n",
      "Sample list:  453\n",
      "385 68\n"
     ]
    }
   ],
   "source": [
    "make_split(\"crow_trap\", dataset_dir=\"Datasets/Crow_classify/train\", split_p=.15)\n",
    "make_split(\"background\", dataset_dir=\"Datasets/Crow_classify/train\", split_p=.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_grey(samples_dir, save_dir):\n",
    "\n",
    "    samples_list = os.listdir(samples_dir)\n",
    "\n",
    "    for sample in samples_list:\n",
    "\n",
    "        sample_img = Image.open(os.path.join(samples_dir, sample))\n",
    "        to_greyscale = transforms.Grayscale()\n",
    "        sample_img = to_greyscale(sample_img)\n",
    "        \n",
    "        sample_img.save(os.path.join(save_dir, sample))\n",
    "\n",
    "to_grey(\"Datasets/Crow_classify_grey/train/background\", \"Datasets/Crow_classify_grey/train/background\")\n",
    "to_grey(\"Datasets/Crow_classify_grey/train/crow_trap\", \"Datasets/Crow_classify_grey/train/crow_trap\")\n",
    "\n",
    "to_grey(\"Datasets/Crow_classify_grey/val/background\", \"Datasets/Crow_classify_grey/val/background\")\n",
    "to_grey(\"Datasets/Crow_classify_grey/val/crow_trap\", \"Datasets/Crow_classify_grey/val/crow_trap\")\n",
    "\n",
    "to_grey(\"Datasets/Crow_evaluate_classify_grey/val/background\", \"Datasets/Crow_evaluate_classify_grey/val/background\")\n",
    "to_grey(\"Datasets/Crow_evaluate_classify_grey/val/crow_trap\", \"Datasets/Crow_evaluate_classify_grey/val/crow_trap\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rspb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
