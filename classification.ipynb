{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train data into train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample list:  45\n",
      "36  in  Datasets/backup/Crow_traps_Subset_patched/train/crow_trap\n",
      "9  in  Datasets/backup/Crow_traps_Subset_patched/test/crow_trap\n",
      "Sample list:  481\n",
      "384  in  Datasets/backup/Crow_traps_Subset_patched/train/background\n",
      "97  in  Datasets/backup/Crow_traps_Subset_patched/test/background\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import make_split\n",
    "\n",
    "make_split(\"crow_trap\", dataset_dir=\"Datasets/backup/Crow_traps_Subset_patched\", split_p=0.2)\n",
    "make_split(\"background\", dataset_dir=\"Datasets/backup/Crow_traps_Subset_patched\", split_p=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "The train split can be used to generate augmented data and reduce imbalance in the dataset.\n",
    "\n",
    "- **background augmentation**: bushes are randomly placed into background images\n",
    "\n",
    "- **crow_trap generation**: Crow traps (previously manually masked out) are placed randomly on background images. At the same time, YOLOv8 annotation files are generated\n",
    "\n",
    "*YOLO annotation format* (https://medium.com/analytics-vidhya/getting-data-annotation-format-right-for-object-detection-tasks-f41b07eebbf5)\n",
    "\n",
    "\n",
    "class x y width height \n",
    "\n",
    "ex: 0 0.25 0.44 0.5 0.8\n",
    "\n",
    "class is the object class, (x,y) are centre coordinates of the bounding box (normalised wrt the size of the image-patch). width, height represent width and height of the bounding box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N samples:  36\n"
     ]
    }
   ],
   "source": [
    "from utils.augmentation import augment_imgs\n",
    "\n",
    "imgs_dir = \"Datasets/Classification/train/background\"\n",
    "augment_imgs(imgs_dir, imgs_dir)\n",
    "\n",
    "imgs_dir = \"Datasets/Classification/train/crow_trap\"\n",
    "augment_imgs(imgs_dir, imgs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crow trap generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample list:  766\n",
      "612  in  Datasets/Classification/train/train/background\n",
      "154  in  Datasets/Classification/train/test/background\n",
      "Sample list:  72\n",
      "57  in  Datasets/Classification/train/train/crow_trap\n",
      "15  in  Datasets/Classification/train/test/crow_trap\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import make_split\n",
    "\n",
    "make_split(\"background\", dataset_dir=\"Datasets/Classification/train\", classify=True, split_p=0.2)\n",
    "make_split(\"crow_trap\", dataset_dir=\"Datasets/Classification/train\", classify=True, split_p=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N samples:  612\n",
      "102563_1_2_aug_1t.png\n",
      "101339_2_0_aug_1t.png\n",
      "101343_3_1_1t.png\n",
      "100459_3_0_1t.png\n",
      "103138_3_2_1t.png\n",
      "104272_3_0_aug_1t.png\n",
      "103638_1_1_1t.png\n",
      "102522_0_1_1t.png\n",
      "104357_0_0_aug_1t.png\n",
      "101339_2_0_1t.png\n",
      "100459_0_0_aug_1t.png\n",
      "101546_1_0_1t.png\n",
      "103849_1_2_aug_1t.png\n",
      "102598_2_2_aug_1t.png\n",
      "104269_3_2_aug_1t.png\n",
      "103303_1_2_1t.png\n",
      "100615_3_0_1t.png\n",
      "104008_3_0_1t.png\n",
      "100980_1_0_1t.png\n",
      "99495_1_1_aug_1t.png\n",
      "102601_2_2_aug_1t.png\n",
      "101550_1_0_aug_1t.png\n",
      "103519_0_2_1t.png\n",
      "100331_1_2_aug_1t.png\n",
      "104268_0_0_aug_1t.png\n",
      "104008_0_0_aug_1t.png\n",
      "100615_0_1_1t.png\n",
      "101679_0_1_1t.png\n",
      "104357_0_0_1t.png\n",
      "101520_0_1_1t.png\n",
      "103519_0_1_aug_1t.png\n",
      "103439_3_2_aug_1t.png\n",
      "101343_0_2_1t.png\n",
      "102523_0_1_aug_1t.png\n",
      "101569_2_2_1t.png\n",
      "102237_2_2_1t.png\n",
      "104269_1_0_1t.png\n",
      "102521_1_1_aug_1t.png\n",
      "102237_0_1_aug_1t.png\n",
      "102563_3_0_aug_1t.png\n",
      "101442_3_0_1t.png\n",
      "99495_3_2_1t.png\n",
      "101559_1_0_aug_1t.png\n",
      "104272_3_1_aug_1t.png\n",
      "101442_1_0_aug_1t.png\n",
      "101125_0_1_1t.png\n",
      "102601_0_1_aug_1t.png\n",
      "104357_2_2_aug_1t.png\n",
      "103303_1_0_1t.png\n",
      "103519_2_0_aug_1t.png\n",
      "100459_0_2_1t.png\n",
      "101559_2_2_1t.png\n",
      "102563_0_0_1t.png\n",
      "101517_3_2_1t.png\n",
      "100459_0_0_1t.png\n",
      "104272_2_0_aug_1t.png\n",
      "101509_1_2_1t.png\n",
      "101559_2_0_1t.png\n",
      "102522_3_1_1t.png\n",
      "103638_2_0_1t.png\n",
      "100331_1_0_1t.png\n",
      "102601_1_0_1t.png\n",
      "101569_1_0_1t.png\n",
      "104268_3_0_aug_1t.png\n",
      "101679_3_2_aug_1t.png\n",
      "100459_3_1_aug_1t.png\n",
      "102523_1_2_1t.png\n",
      "101559_2_2_aug_1t.png\n",
      "100331_1_2_1t.png\n",
      "102601_3_2_aug_1t.png\n",
      "104268_0_2_1t.png\n",
      "102598_3_0_1t.png\n",
      "104357_2_0_aug_1t.png\n",
      "101164_1_0_1t.png\n",
      "101509_0_2_1t.png\n",
      "99911_3_2_1t.png\n",
      "103439_1_1_aug_1t.png\n",
      "101559_0_1_aug_1t.png\n",
      "101520_2_0_aug_1t.png\n",
      "101125_1_1_1t.png\n",
      "101343_0_2_aug_1t.png\n",
      "102563_1_0_1t.png\n",
      "101679_1_1_aug_1t.png\n",
      "102601_2_2_1t.png\n",
      "102523_1_2_aug_1t.png\n",
      "103849_2_0_aug_1t.png\n",
      "104201_1_0_aug_1t.png\n",
      "104272_3_2_aug_1t.png\n",
      "102237_0_1_1t.png\n",
      "104201_1_2_aug_1t.png\n",
      "102563_3_0_1t.png\n",
      "104272_1_0_aug_1t.png\n",
      "102523_0_0_aug_1t.png\n",
      "100631_1_1_1t.png\n",
      "101343_2_2_1t.png\n",
      "101339_3_1_aug_1t.png\n",
      "102521_0_0_1t.png\n",
      "101548_1_2_1t.png\n",
      "102601_1_1_1t.png\n",
      "99911_3_0_aug_1t.png\n",
      "102237_3_1_1t.png\n",
      "103303_3_2_1t.png\n",
      "101123_0_1_aug_1t.png\n",
      "100331_3_0_1t.png\n",
      "104008_3_1_aug_1t.png\n",
      "103303_3_0_1t.png\n",
      "103439_0_2_aug_1t.png\n",
      "101509_3_0_aug_1t.png\n",
      "103303_3_2_aug_1t.png\n",
      "104270_0_1_1t.png\n",
      "102237_0_0_aug_1t.png\n",
      "100615_2_2_aug_1t.png\n",
      "99495_0_2_1t.png\n",
      "102521_0_2_1t.png\n",
      "102523_3_2_aug_1t.png\n",
      "101559_1_0_1t.png\n",
      "102237_2_0_aug_1t.png\n",
      "101123_2_2_aug_1t.png\n",
      "103303_0_2_aug_1t.png\n",
      "102522_1_1_1t.png\n",
      "104008_1_0_aug_1t.png\n",
      "102521_0_1_1t.png\n",
      "101339_0_2_aug_1t.png\n",
      "104008_0_1_1t.png\n",
      "104357_3_1_aug_1t.png\n",
      "99495_3_1_1t.png\n",
      "104272_3_2_1t.png\n",
      "104268_3_1_1t.png\n",
      "103638_3_1_1t.png\n",
      "104270_1_1_1t.png\n",
      "102523_0_2_1t.png\n",
      "101517_0_1_1t.png\n",
      "103710_0_2_aug_1t.png\n",
      "101569_0_0_1t.png\n",
      "100980_3_2_aug_1t.png\n",
      "104201_0_0_aug_1t.png\n",
      "102523_0_0_1t.png\n",
      "100615_2_2_1t.png\n",
      "99911_0_1_aug_1t.png\n",
      "99495_3_2_aug_1t.png\n",
      "103519_3_0_1t.png\n",
      "100459_0_1_aug_1t.png\n",
      "104201_3_0_1t.png\n",
      "103439_1_1_1t.png\n",
      "101123_0_1_1t.png\n",
      "101442_0_2_aug_1t.png\n",
      "101125_1_2_aug_1t.png\n",
      "102521_3_0_1t.png\n",
      "100459_0_2_aug_1t.png\n",
      "99911_0_1_1t.png\n",
      "101520_1_2_1t.png\n",
      "102563_3_1_aug_1t.png\n",
      "104201_3_0_aug_1t.png\n",
      "99495_3_0_1t.png\n",
      "102521_3_0_aug_1t.png\n",
      "102237_3_0_1t.png\n",
      "101546_3_2_1t.png\n",
      "101517_1_1_aug_1t.png\n",
      "103849_3_0_1t.png\n",
      "101509_3_1_1t.png\n",
      "104357_2_2_1t.png\n",
      "101339_1_0_1t.png\n",
      "101509_1_1_1t.png\n",
      "103138_0_1_aug_1t.png\n",
      "101546_2_2_aug_1t.png\n",
      "100615_0_0_aug_1t.png\n",
      "101520_3_0_aug_1t.png\n",
      "104270_2_2_1t.png\n",
      "104008_1_1_1t.png\n",
      "102522_1_2_1t.png\n",
      "100631_1_2_1t.png\n",
      "101517_3_1_aug_1t.png\n",
      "101546_0_0_1t.png\n",
      "101509_3_2_aug_1t.png\n",
      "102601_2_0_aug_1t.png\n",
      "101339_3_2_1t.png\n",
      "102521_1_1_1t.png\n",
      "104201_0_2_aug_1t.png\n",
      "102237_1_1_aug_1t.png\n",
      "103519_1_1_1t.png\n",
      "99911_1_0_1t.png\n",
      "104357_3_2_aug_1t.png\n",
      "100980_3_1_1t.png\n",
      "102601_0_2_aug_1t.png\n",
      "104268_1_1_1t.png\n",
      "101546_0_0_aug_1t.png\n",
      "102237_0_2_aug_1t.png\n",
      "101550_2_2_1t.png\n",
      "103519_0_0_1t.png\n",
      "101123_1_2_1t.png\n",
      "100331_3_2_1t.png\n",
      "100980_3_2_1t.png\n",
      "100980_1_0_aug_1t.png\n",
      "101569_2_2_aug_1t.png\n",
      "100459_0_1_1t.png\n",
      "102520_1_0_aug_1t.png\n",
      "101123_2_0_1t.png\n",
      "102237_1_1_1t.png\n",
      "103439_1_0_1t.png\n",
      "101343_3_2_aug_1t.png\n",
      "104008_0_1_aug_1t.png\n",
      "99245_0_0_aug_1t.png\n",
      "104269_1_0_aug_1t.png\n",
      "102523_1_1_aug_1t.png\n",
      "100615_0_0_1t.png\n",
      "104272_1_1_1t.png\n",
      "102520_3_0_aug_1t.png\n",
      "101520_0_1_aug_1t.png\n",
      "100331_3_0_aug_1t.png\n",
      "102598_1_2_1t.png\n",
      "100631_0_2_aug_1t.png\n",
      "104268_0_1_aug_1t.png\n",
      "101550_3_0_aug_1t.png\n",
      "101123_3_0_aug_1t.png\n",
      "103638_2_1_aug_1t.png\n",
      "104008_2_2_aug_1t.png\n",
      "101343_1_0_1t.png\n",
      "101550_1_1_aug_1t.png\n",
      "99911_2_0_1t.png\n",
      "99911_0_0_1t.png\n",
      "101442_1_0_1t.png\n",
      "101679_3_2_1t.png\n",
      "104270_2_2_aug_1t.png\n",
      "104008_1_1_aug_1t.png\n",
      "99911_3_0_1t.png\n",
      "104201_2_2_1t.png\n",
      "102520_3_1_1t.png\n",
      "103519_1_0_aug_1t.png\n",
      "99495_0_1_aug_1t.png\n",
      "99911_3_2_aug_1t.png\n",
      "104027_1_0_aug_1t.png\n",
      "102598_3_1_aug_1t.png\n",
      "100631_2_2_aug_1t.png\n",
      "103519_0_2_aug_1t.png\n",
      "104268_0_0_1t.png\n",
      "102523_3_1_aug_1t.png\n",
      "99495_0_0_1t.png\n",
      "104268_1_2_1t.png\n",
      "101517_1_1_1t.png\n",
      "104269_1_2_aug_1t.png\n",
      "101509_3_0_1t.png\n",
      "102522_3_0_aug_1t.png\n",
      "101559_1_1_1t.png\n",
      "102520_3_1_aug_1t.png\n",
      "101343_0_0_aug_1t.png\n",
      "104272_3_0_1t.png\n",
      "103138_0_0_aug_1t.png\n",
      "103138_1_1_1t.png\n",
      "103638_1_1_aug_1t.png\n",
      "102523_2_2_1t.png\n",
      "100331_0_1_1t.png\n",
      "101123_3_1_1t.png\n",
      "103710_1_0_aug_1t.png\n",
      "101569_0_2_1t.png\n",
      "101442_2_0_aug_1t.png\n",
      "102563_0_2_1t.png\n",
      "104268_1_0_1t.png\n",
      "104270_0_2_aug_1t.png\n",
      "104270_0_2_1t.png\n",
      "103710_3_2_1t.png\n",
      "103519_1_0_1t.png\n",
      "104008_1_2_1t.png\n",
      "102523_1_0_aug_1t.png\n",
      "101559_0_2_1t.png\n",
      "101343_3_0_aug_1t.png\n",
      "103710_2_2_1t.png\n",
      "103303_3_0_aug_1t.png\n",
      "103710_2_0_1t.png\n",
      "101548_0_1_aug_1t.png\n",
      "101339_1_0_aug_1t.png\n",
      "100331_0_0_aug_1t.png\n",
      "103138_0_1_1t.png\n",
      "101548_3_2_1t.png\n",
      "104008_0_2_1t.png\n",
      "104201_2_0_aug_1t.png\n",
      "101509_0_1_1t.png\n",
      "101546_3_0_1t.png\n",
      "102598_1_2_aug_1t.png\n",
      "101509_3_1_aug_1t.png\n",
      "101442_0_1_1t.png\n",
      "101517_2_0_1t.png\n",
      "103138_0_2_aug_1t.png\n",
      "101679_3_1_aug_1t.png\n",
      "101546_0_1_1t.png\n",
      "103638_0_0_aug_1t.png\n",
      "101679_0_0_aug_1t.png\n",
      "102522_2_2_1t.png\n",
      "99911_2_2_1t.png\n",
      "101548_0_1_1t.png\n",
      "103638_3_1_aug_1t.png\n",
      "104272_1_0_1t.png\n",
      "101559_3_0_aug_1t.png\n",
      "104270_3_1_1t.png\n",
      "103303_2_0_1t.png\n",
      "101125_0_2_1t.png\n",
      "100631_1_1_aug_1t.png\n",
      "101509_2_2_aug_1t.png\n",
      "101517_0_2_aug_1t.png\n",
      "102237_3_2_aug_1t.png\n",
      "101546_3_2_aug_1t.png\n",
      "101442_3_2_aug_1t.png\n",
      "103138_3_1_1t.png\n",
      "99495_2_0_aug_1t.png\n",
      "101548_2_0_1t.png\n",
      "99911_1_2_aug_1t.png\n",
      "104270_3_1_aug_1t.png\n",
      "101520_1_1_1t.png\n",
      "102523_0_1_1t.png\n",
      "100615_1_0_aug_1t.png\n",
      "103849_2_2_1t.png\n",
      "99495_0_2_aug_1t.png\n",
      "104268_1_1_aug_1t.png\n",
      "102520_0_1_1t.png\n",
      "102521_3_1_aug_1t.png\n",
      "102521_0_1_aug_1t.png\n",
      "102522_1_2_aug_1t.png\n",
      "101125_1_2_1t.png\n",
      "101509_0_1_aug_1t.png\n",
      "102237_3_0_aug_1t.png\n",
      "103849_2_2_aug_1t.png\n",
      "101548_1_0_1t.png\n",
      "103710_3_1_aug_1t.png\n",
      "100631_0_0_1t.png\n",
      "103303_0_0_aug_1t.png\n",
      "101442_1_2_1t.png\n",
      "103849_3_0_aug_1t.png\n",
      "104272_1_1_aug_1t.png\n",
      "101679_0_0_1t.png\n",
      "104270_1_2_1t.png\n",
      "104357_3_1_1t.png\n",
      "104357_3_2_1t.png\n",
      "100631_2_2_1t.png\n",
      "99495_1_2_1t.png\n",
      "101442_1_2_aug_1t.png\n",
      "104008_2_0_aug_1t.png\n",
      "99495_0_0_aug_1t.png\n",
      "103710_0_2_1t.png\n",
      "100459_2_2_aug_1t.png\n",
      "99495_0_1_1t.png\n",
      "101343_1_2_1t.png\n",
      "101343_3_0_1t.png\n",
      "102521_2_0_aug_1t.png\n",
      "101125_0_1_aug_1t.png\n",
      "103849_2_0_1t.png\n",
      "102601_3_1_aug_1t.png\n",
      "101550_1_0_1t.png\n",
      "103638_3_0_1t.png\n",
      "101550_3_2_aug_1t.png\n",
      "103519_2_2_aug_1t.png\n",
      "101550_1_2_aug_1t.png\n",
      "101123_0_2_aug_1t.png\n",
      "99911_2_0_aug_1t.png\n",
      "101442_2_0_1t.png\n",
      "101509_3_2_1t.png\n",
      "104268_3_2_aug_1t.png\n",
      "103138_2_2_aug_1t.png\n",
      "102521_3_2_aug_1t.png\n",
      "101569_1_2_1t.png\n",
      "102601_3_2_1t.png\n",
      "101343_1_2_aug_1t.png\n",
      "104008_3_1_1t.png\n",
      "102521_2_0_1t.png\n",
      "102521_0_2_aug_1t.png\n",
      "104270_1_2_aug_1t.png\n",
      "104008_3_0_aug_1t.png\n",
      "102523_1_1_1t.png\n",
      "104269_0_1_1t.png\n",
      "103519_3_2_1t.png\n",
      "102598_3_0_aug_1t.png\n",
      "104272_0_1_aug_1t.png\n",
      "102598_0_0_1t.png\n",
      "102563_3_1_1t.png\n",
      "101548_2_2_1t.png\n",
      "103138_1_1_aug_1t.png\n",
      "103519_3_0_aug_1t.png\n",
      "102601_3_1_1t.png\n",
      "101123_2_0_aug_1t.png\n",
      "102520_2_0_1t.png\n",
      "101123_0_2_1t.png\n",
      "101548_3_0_1t.png\n",
      "100459_2_2_1t.png\n",
      "101569_2_0_aug_1t.png\n",
      "103710_3_1_1t.png\n",
      "101569_1_2_aug_1t.png\n",
      "101546_0_1_aug_1t.png\n",
      "101569_3_2_aug_1t.png\n",
      "101343_2_0_aug_1t.png\n",
      "99495_1_2_aug_1t.png\n",
      "100631_1_2_aug_1t.png\n",
      "103638_0_1_1t.png\n",
      "103710_1_1_1t.png\n",
      "101164_0_0_aug_1t.png\n",
      "102520_0_1_aug_1t.png\n",
      "103519_1_1_aug_1t.png\n",
      "101550_0_1_aug_1t.png\n",
      "104272_1_2_1t.png\n",
      "102523_0_2_aug_1t.png\n",
      "101550_1_2_1t.png\n",
      "101509_1_1_aug_1t.png\n",
      "100459_3_2_aug_1t.png\n",
      "103638_3_0_aug_1t.png\n",
      "103849_1_2_1t.png\n",
      "101517_3_0_1t.png\n",
      "103638_2_1_1t.png\n",
      "104268_1_0_aug_1t.png\n",
      "104269_0_0_aug_1t.png\n",
      "99911_3_1_aug_1t.png\n",
      "102601_3_0_1t.png\n",
      "101550_0_2_aug_1t.png\n",
      "102598_3_1_1t.png\n",
      "103638_2_2_1t.png\n",
      "103138_2_2_1t.png\n",
      "101559_0_2_aug_1t.png\n",
      "101343_2_0_1t.png\n",
      "103710_3_2_aug_1t.png\n",
      "101343_1_0_aug_1t.png\n",
      "99911_0_0_aug_1t.png\n",
      "101548_1_2_aug_1t.png\n",
      "104268_2_0_aug_1t.png\n",
      "102520_1_0_1t.png\n",
      "102598_1_0_1t.png\n",
      "103439_3_0_aug_1t.png\n",
      "104008_2_2_1t.png\n",
      "102522_1_1_aug_1t.png\n",
      "101164_0_0_1t.png\n",
      "102563_1_2_1t.png\n",
      "102563_2_0_aug_1t.png\n",
      "100631_1_0_1t.png\n",
      "104201_0_1_aug_1t.png\n",
      "99245_0_0_1t.png\n",
      "103439_0_1_1t.png\n",
      "102598_2_2_1t.png\n",
      "104269_2_2_aug_1t.png\n",
      "100631_0_0_aug_1t.png\n",
      "102601_1_0_aug_1t.png\n",
      "101442_2_2_1t.png\n",
      "103849_1_0_aug_1t.png\n",
      "101550_0_0_aug_1t.png\n",
      "102563_2_1_1t.png\n",
      "103710_1_1_aug_1t.png\n",
      "101550_3_1_1t.png\n",
      "99911_1_2_1t.png\n",
      "103439_2_2_1t.png\n",
      "104272_0_2_1t.png\n",
      "100980_2_0_aug_1t.png\n",
      "102601_2_0_1t.png\n",
      "104357_0_2_1t.png\n",
      "102237_3_2_1t.png\n",
      "104269_3_0_aug_1t.png\n",
      "102563_0_2_aug_1t.png\n",
      "101343_0_0_1t.png\n",
      "102601_0_2_1t.png\n",
      "104269_0_1_aug_1t.png\n",
      "103439_2_2_aug_1t.png\n",
      "101559_1_1_aug_1t.png\n",
      "100631_3_1_1t.png\n",
      "104269_3_2_1t.png\n",
      "103138_2_0_aug_1t.png\n",
      "101546_2_2_1t.png\n",
      "101550_0_2_1t.png\n",
      "101125_3_1_aug_1t.png\n",
      "102563_2_1_aug_1t.png\n",
      "102520_3_0_1t.png\n",
      "103439_0_2_1t.png\n",
      "101559_3_0_1t.png\n",
      "101679_0_2_aug_1t.png\n",
      "104268_2_2_1t.png\n",
      "101569_0_0_aug_1t.png\n",
      "100980_1_2_1t.png\n",
      "103519_2_0_1t.png\n",
      "101520_3_2_1t.png\n",
      "101559_3_2_aug_1t.png\n",
      "101125_2_2_1t.png\n",
      "104269_2_0_aug_1t.png\n",
      "101569_2_0_1t.png\n",
      "104270_3_2_1t.png\n",
      "103519_0_1_1t.png\n",
      "101517_1_0_1t.png\n",
      "103303_1_2_aug_1t.png\n",
      "104201_0_1_1t.png\n",
      "101339_2_2_aug_1t.png\n",
      "103138_1_0_1t.png\n",
      "104008_2_0_1t.png\n",
      "100331_0_0_1t.png\n",
      "100631_1_0_aug_1t.png\n",
      "103638_0_2_1t.png\n",
      "102520_0_0_aug_1t.png\n",
      "100980_0_2_aug_1t.png\n",
      "103638_2_0_aug_1t.png\n",
      "101569_0_2_aug_1t.png\n",
      "103519_3_2_aug_1t.png\n",
      "99911_2_2_aug_1t.png\n",
      "102521_1_0_aug_1t.png\n",
      "104357_2_0_1t.png\n",
      "102521_1_0_1t.png\n",
      "101546_1_2_1t.png\n",
      "104270_1_1_aug_1t.png\n",
      "101550_1_1_1t.png\n",
      "103303_2_2_1t.png\n",
      "104269_2_2_1t.png\n",
      "101548_3_2_aug_1t.png\n",
      "101569_3_1_aug_1t.png\n",
      "103849_1_1_1t.png\n",
      "102237_0_0_1t.png\n",
      "101442_3_2_1t.png\n",
      "104272_3_1_1t.png\n",
      "103138_3_0_aug_1t.png\n",
      "104269_2_0_1t.png\n",
      "104272_1_2_aug_1t.png\n",
      "103439_3_0_1t.png\n",
      "101343_2_2_aug_1t.png\n",
      "103303_1_0_aug_1t.png\n",
      "102520_3_2_1t.png\n",
      "101442_0_1_aug_1t.png\n",
      "103638_1_2_aug_1t.png\n",
      "101343_3_2_1t.png\n",
      "104272_2_0_1t.png\n",
      "104270_3_2_aug_1t.png\n",
      "100615_1_0_1t.png\n",
      "102598_0_2_1t.png\n",
      "101125_2_2_aug_1t.png\n",
      "103138_3_2_aug_1t.png\n",
      "104201_1_0_1t.png\n",
      "103638_0_0_1t.png\n",
      "104268_1_2_aug_1t.png\n",
      "104268_3_0_1t.png\n",
      "103303_0_1_1t.png\n",
      "104268_3_1_aug_1t.png\n",
      "99911_3_1_1t.png\n",
      "102237_2_2_aug_1t.png\n",
      "101123_3_0_1t.png\n",
      "102601_3_0_aug_1t.png\n",
      "99495_3_1_aug_1t.png\n",
      "104272_0_1_1t.png\n",
      "103138_2_0_1t.png\n",
      "102520_1_1_1t.png\n",
      "102563_0_1_aug_1t.png\n",
      "101520_3_2_aug_1t.png\n",
      "100631_3_0_1t.png\n",
      "104008_3_2_aug_1t.png\n",
      "104201_2_0_1t.png\n",
      "103303_1_1_aug_1t.png\n",
      "100980_0_0_1t.png\n",
      "101520_1_1_aug_1t.png\n",
      "100631_3_2_1t.png\n",
      "101548_1_0_aug_1t.png\n",
      "102563_3_2_aug_1t.png\n",
      "103303_0_2_1t.png\n",
      "101548_0_0_aug_1t.png\n",
      "103710_0_1_aug_1t.png\n",
      "102237_2_0_1t.png\n",
      "102598_0_2_aug_1t.png\n",
      "103710_1_0_1t.png\n",
      "100980_0_0_aug_1t.png\n",
      "101546_0_2_1t.png\n",
      "101548_2_0_aug_1t.png\n",
      "102237_1_2_1t.png\n",
      "102563_0_1_1t.png\n",
      "104008_3_2_1t.png\n",
      "101339_0_2_1t.png\n",
      "101546_1_0_aug_1t.png\n",
      "101559_0_1_1t.png\n",
      "104270_0_0_aug_1t.png\n",
      "103439_1_0_aug_1t.png\n",
      "101559_3_2_1t.png\n",
      "102237_1_0_1t.png\n",
      "101550_3_0_1t.png\n",
      "102601_0_1_1t.png\n",
      "99911_1_0_aug_1t.png\n",
      "102523_3_1_1t.png\n",
      "104201_0_2_1t.png\n",
      "103710_0_0_aug_1t.png\n",
      "101679_3_1_1t.png\n",
      "103710_3_0_1t.png\n",
      "100980_0_2_1t.png\n",
      "102520_1_2_1t.png\n",
      "99495_3_0_aug_1t.png\n",
      "102237_1_2_aug_1t.png\n",
      "103439_0_1_aug_1t.png\n",
      "103303_0_1_aug_1t.png\n",
      "102522_2_0_aug_1t.png\n",
      "104269_3_1_aug_1t.png\n",
      "101679_3_0_aug_1t.png\n",
      "103849_1_1_aug_1t.png\n",
      "102523_2_2_aug_1t.png\n",
      "104201_1_1_1t.png\n",
      "104201_0_0_1t.png\n",
      "101517_3_0_aug_1t.png\n",
      "101509_1_2_aug_1t.png\n",
      "101679_1_1_1t.png\n",
      "101520_1_2_aug_1t.png\n",
      "100631_0_1_1t.png\n",
      "102563_2_0_1t.png\n",
      "100980_2_0_1t.png\n",
      "101339_3_2_aug_1t.png\n",
      "101509_2_2_1t.png\n",
      "103138_3_1_aug_1t.png\n",
      "101546_0_2_aug_1t.png\n",
      "103303_2_2_aug_1t.png\n",
      "99495_1_0_1t.png\n",
      "104201_1_2_1t.png\n",
      "104268_2_2_aug_1t.png\n",
      "101125_3_0_aug_1t.png\n",
      "101339_3_1_1t.png\n",
      "103638_0_1_aug_1t.png\n",
      "101125_1_1_aug_1t.png\n",
      "102522_0_2_aug_1t.png\n",
      "101164_1_0_aug_1t.png\n",
      "101550_3_1_aug_1t.png\n",
      "99495_2_0_1t.png\n",
      "101679_2_0_aug_1t.png\n",
      "101569_1_0_aug_1t.png\n"
     ]
    }
   ],
   "source": [
    "from utils.augmentation import add_traps\n",
    "\n",
    "back_dir = \"Datasets/Classification/train/background/\"\n",
    "trap_dir = \"Datasets/Classification/traps/train\"\n",
    "save_img_dir = \"Datasets/Classification/train/crow_trap\"\n",
    "\n",
    "add_traps(\n",
    "    back_dir,\n",
    "    trap_dir,\n",
    "    save_img_dir,\n",
    "    n_min=1,\n",
    "    n_max=2,\n",
    "    p_distribution=[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N samples:  154\n",
      "101520_2_0_1t.png\n",
      "104201_1_1_aug_1t.png\n",
      "101517_0_2_1t.png\n",
      "101123_2_2_1t.png\n",
      "101546_1_2_aug_1t.png\n",
      "104268_2_0_1t.png\n",
      "100615_1_1_aug_1t.png\n",
      "103138_1_0_aug_1t.png\n",
      "101517_0_1_aug_1t.png\n",
      "102601_1_1_aug_1t.png\n",
      "101339_2_2_1t.png\n",
      "102237_0_2_1t.png\n",
      "102563_1_0_aug_1t.png\n",
      "99911_0_2_1t.png\n",
      "103303_0_0_1t.png\n",
      "100331_0_1_aug_1t.png\n",
      "103519_2_2_1t.png\n",
      "104008_1_2_aug_1t.png\n",
      "102520_1_2_aug_1t.png\n",
      "102522_2_2_aug_1t.png\n",
      "102521_3_2_1t.png\n",
      "104027_1_0_1t.png\n",
      "103849_3_2_aug_1t.png\n",
      "103638_0_2_aug_1t.png\n",
      "101123_1_1_aug_1t.png\n",
      "102563_3_2_1t.png\n",
      "101550_2_2_aug_1t.png\n",
      "101569_3_1_1t.png\n",
      "101517_3_1_1t.png\n",
      "101550_0_1_1t.png\n",
      "101520_0_2_1t.png\n",
      "102522_3_1_aug_1t.png\n",
      "102520_1_1_aug_1t.png\n",
      "100459_3_1_1t.png\n",
      "103638_2_2_aug_1t.png\n",
      "101125_3_0_1t.png\n",
      "102598_1_0_aug_1t.png\n",
      "101517_1_2_aug_1t.png\n",
      "100980_1_1_aug_1t.png\n",
      "100631_3_1_aug_1t.png\n",
      "100631_3_2_aug_1t.png\n",
      "102522_2_0_1t.png\n",
      "104201_2_2_aug_1t.png\n",
      "101125_3_1_1t.png\n",
      "103849_1_0_1t.png\n",
      "101517_1_2_1t.png\n",
      "103519_0_0_aug_1t.png\n",
      "104268_0_1_1t.png\n",
      "99911_1_1_aug_1t.png\n",
      "100331_1_0_aug_1t.png\n",
      "102521_2_2_1t.png\n",
      "100980_3_1_aug_1t.png\n",
      "101520_0_2_aug_1t.png\n",
      "100631_0_1_aug_1t.png\n",
      "104270_0_1_aug_1t.png\n",
      "101442_1_1_1t.png\n",
      "104272_0_0_1t.png\n",
      "104357_0_2_aug_1t.png\n",
      "101548_3_0_aug_1t.png\n",
      "101559_2_0_aug_1t.png\n",
      "104272_0_2_aug_1t.png\n",
      "101442_2_2_aug_1t.png\n",
      "103710_3_0_aug_1t.png\n",
      "102237_3_1_aug_1t.png\n",
      "103638_1_2_1t.png\n",
      "104008_1_0_1t.png\n",
      "104269_3_1_1t.png\n",
      "104268_0_2_aug_1t.png\n",
      "101517_2_0_aug_1t.png\n",
      "104269_0_0_1t.png\n",
      "101442_3_0_aug_1t.png\n",
      "103138_0_2_1t.png\n",
      "101442_0_2_1t.png\n",
      "103710_2_2_aug_1t.png\n",
      "100459_3_0_aug_1t.png\n",
      "100615_0_1_aug_1t.png\n",
      "101546_3_0_aug_1t.png\n",
      "103710_0_0_1t.png\n",
      "102523_1_0_1t.png\n",
      "101442_1_1_aug_1t.png\n",
      "99495_1_1_1t.png\n",
      "100980_1_2_aug_1t.png\n",
      "103519_1_2_1t.png\n",
      "104272_0_0_aug_1t.png\n",
      "100615_1_2_1t.png\n",
      "101548_2_2_aug_1t.png\n",
      "102521_2_2_aug_1t.png\n",
      "100615_1_2_aug_1t.png\n",
      "101520_3_0_1t.png\n",
      "100980_1_1_1t.png\n",
      "103439_3_2_1t.png\n",
      "104008_0_0_1t.png\n",
      "102522_0_2_1t.png\n",
      "101548_0_0_1t.png\n",
      "104008_0_2_aug_1t.png\n",
      "101679_2_2_1t.png\n",
      "101569_1_1_aug_1t.png\n",
      "100615_3_0_aug_1t.png\n",
      "102522_3_0_1t.png\n",
      "104270_3_0_aug_1t.png\n",
      "101679_2_0_1t.png\n",
      "99911_1_1_1t.png\n",
      "101548_3_1_1t.png\n",
      "101123_3_1_aug_1t.png\n",
      "103519_1_2_aug_1t.png\n",
      "101679_0_2_1t.png\n",
      "102563_0_0_aug_1t.png\n",
      "103138_0_0_1t.png\n",
      "103849_3_2_1t.png\n",
      "103303_1_1_1t.png\n",
      "101550_3_2_1t.png\n",
      "101343_3_1_aug_1t.png\n",
      "100631_3_0_aug_1t.png\n",
      "102520_3_2_aug_1t.png\n",
      "103710_0_1_1t.png\n",
      "101517_3_2_aug_1t.png\n",
      "104269_3_0_1t.png\n",
      "99911_0_2_aug_1t.png\n",
      "102521_0_0_aug_1t.png\n",
      "104270_1_0_aug_1t.png\n",
      "100459_3_2_1t.png\n",
      "101569_3_2_1t.png\n",
      "102522_0_1_aug_1t.png\n",
      "102521_3_1_1t.png\n",
      "101123_1_1_1t.png\n",
      "101509_0_2_aug_1t.png\n",
      "101550_0_0_1t.png\n",
      "101548_3_1_aug_1t.png\n",
      "102598_0_0_aug_1t.png\n",
      "103303_2_0_aug_1t.png\n",
      "101509_2_0_1t.png\n",
      "104269_1_2_1t.png\n",
      "100331_3_2_aug_1t.png\n",
      "100615_1_1_1t.png\n",
      "101569_1_1_1t.png\n",
      "101679_2_2_aug_1t.png\n",
      "101679_3_0_1t.png\n",
      "104270_0_0_1t.png\n",
      "104270_1_0_1t.png\n",
      "102237_1_0_aug_1t.png\n",
      "104268_3_2_1t.png\n",
      "102520_2_0_aug_1t.png\n",
      "101509_2_0_aug_1t.png\n",
      "104270_3_0_1t.png\n",
      "102523_3_2_1t.png\n",
      "101517_1_0_aug_1t.png\n",
      "100631_0_2_1t.png\n",
      "101123_1_2_aug_1t.png\n",
      "102520_0_0_1t.png\n",
      "101679_0_1_aug_1t.png\n",
      "101125_0_2_aug_1t.png\n",
      "103710_2_0_aug_1t.png\n",
      "103138_3_0_1t.png\n",
      "99495_1_0_aug_1t.png\n"
     ]
    }
   ],
   "source": [
    "from utils.augmentation import add_traps\n",
    "\n",
    "back_dir = \"Datasets/Classification/val/background/\"\n",
    "trap_dir = \"Datasets/Classification/traps/val\"\n",
    "save_img_dir = \"Datasets/Classification/val/crow_trap\"\n",
    "\n",
    "add_traps(\n",
    "    back_dir,\n",
    "    trap_dir,\n",
    "    save_img_dir,\n",
    "    n_min=1,\n",
    "    n_max=2,\n",
    "    p_distribution=[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.210 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.193 🚀 Python-3.11.5 torch-2.1.0+cu121 CUDA:0 (NVIDIA GeForce GTX 1060 6GB, 6070MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=Datasets/Classification, epochs=30, patience=50, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train2\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/train... found 1281 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/val... found 323 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test... found 107 images in 2 classes ✅ \n",
      "Overriding model.yaml nc=1000 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
      "YOLOv8n-cls summary: 99 layers, 1440850 parameters, 1440850 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/train... 1281 images, 0 corrupt: 100%|██████████| 1281/1281 [00:00<00:00, 5578.93it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/val... 323 images, 0 corrupt: 100%|██████████| 323/323 [00:00<00:00, 2335.27it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/train2\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       1/30     0.329G     0.1645          1        224: 100%|██████████| 81/81 [00:04<00:00, 19.28it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 44.42it/s]\n",
      "                   all      0.777          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       2/30     0.329G    0.08578          1        224: 100%|██████████| 81/81 [00:03<00:00, 26.80it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 58.88it/s]\n",
      "                   all      0.864          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       3/30     0.329G    0.04025          1        224: 100%|██████████| 81/81 [00:02<00:00, 27.62it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 59.71it/s]\n",
      "                   all      0.858          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       4/30     0.329G    0.03741          1        224: 100%|██████████| 81/81 [00:02<00:00, 28.43it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 60.61it/s]\n",
      "                   all      0.879          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       5/30     0.329G    0.02294          1        224: 100%|██████████| 81/81 [00:02<00:00, 28.38it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 59.77it/s]\n",
      "                   all      0.898          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       6/30     0.329G    0.01501          1        224: 100%|██████████| 81/81 [00:02<00:00, 27.96it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 57.14it/s]\n",
      "                   all      0.898          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       7/30     0.329G    0.01382          1        224: 100%|██████████| 81/81 [00:02<00:00, 27.76it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 59.60it/s]\n",
      "                   all      0.858          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       8/30     0.329G   0.008117          1        224: 100%|██████████| 81/81 [00:02<00:00, 27.70it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 58.52it/s]\n",
      "                   all      0.873          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       9/30     0.329G    0.01238          1        224: 100%|██████████| 81/81 [00:02<00:00, 27.87it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 59.67it/s]\n",
      "                   all      0.858          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      10/30     0.329G     0.0131          1        224: 100%|██████████| 81/81 [00:02<00:00, 28.19it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 58.81it/s]\n",
      "                   all      0.882          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      11/30     0.329G    0.01233          1        224: 100%|██████████| 81/81 [00:02<00:00, 28.09it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 60.51it/s]\n",
      "                   all      0.873          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      12/30     0.329G     0.0117          1        224: 100%|██████████| 81/81 [00:02<00:00, 27.72it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 60.73it/s]\n",
      "                   all      0.867          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      13/30     0.329G    0.00615          1        224: 100%|██████████| 81/81 [00:02<00:00, 27.82it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 58.67it/s]\n",
      "                   all      0.861          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      14/30     0.329G   0.003777          1        224: 100%|██████████| 81/81 [00:02<00:00, 28.16it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 61.56it/s]\n",
      "                   all      0.889          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      15/30     0.329G    0.00428          1        224: 100%|██████████| 81/81 [00:02<00:00, 29.64it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 62.57it/s]\n",
      "                   all      0.873          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      16/30     0.329G   0.003027          1        224: 100%|██████████| 81/81 [00:02<00:00, 29.47it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 63.27it/s]\n",
      "                   all      0.882          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      17/30     0.329G   0.001614          1        224: 100%|██████████| 81/81 [00:02<00:00, 29.19it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 58.32it/s]\n",
      "                   all      0.885          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      18/30     0.329G    0.00195          1        224: 100%|██████████| 81/81 [00:02<00:00, 29.38it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 61.85it/s]\n",
      "                   all      0.861          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      19/30     0.329G  0.0009409          1        224: 100%|██████████| 81/81 [00:02<00:00, 28.63it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 59.60it/s]\n",
      "                   all      0.876          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      20/30     0.329G  0.0006425          1        224: 100%|██████████| 81/81 [00:02<00:00, 29.58it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 62.85it/s]\n",
      "                   all      0.892          1\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      21/30     0.329G  0.0009584          1        224: 100%|██████████| 81/81 [00:02<00:00, 27.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 61.87it/s]\n",
      "                   all      0.876          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      22/30     0.329G   0.001823          1        224: 100%|██████████| 81/81 [00:02<00:00, 29.62it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 61.95it/s]\n",
      "                   all      0.867          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      23/30     0.329G   0.001424          1        224: 100%|██████████| 81/81 [00:02<00:00, 29.39it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 61.48it/s]\n",
      "                   all      0.876          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      24/30     0.329G  0.0003182          1        224: 100%|██████████| 81/81 [00:02<00:00, 29.72it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 63.34it/s]\n",
      "                   all      0.889          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      25/30     0.329G   0.001126          1        224: 100%|██████████| 81/81 [00:02<00:00, 29.49it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 64.50it/s]\n",
      "                   all      0.879          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      26/30     0.329G  0.0005233          1        224: 100%|██████████| 81/81 [00:02<00:00, 29.01it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 61.67it/s]\n",
      "                   all      0.882          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      27/30     0.329G   0.002002          1        224: 100%|██████████| 81/81 [00:02<00:00, 27.96it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 58.98it/s]\n",
      "                   all      0.864          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      28/30     0.329G  0.0004472          1        224: 100%|██████████| 81/81 [00:02<00:00, 28.18it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 59.60it/s]\n",
      "                   all      0.867          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      29/30     0.329G  0.0004873          1        224: 100%|██████████| 81/81 [00:02<00:00, 28.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 59.55it/s]\n",
      "                   all      0.873          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      30/30     0.329G  0.0004036          1        224: 100%|██████████| 81/81 [00:02<00:00, 27.93it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 49.39it/s]\n",
      "                   all      0.842          1\n",
      "\n",
      "30 epochs completed in 0.027 hours.\n",
      "Optimizer stripped from runs/classify/train2/weights/last.pt, 3.0MB\n",
      "Optimizer stripped from runs/classify/train2/weights/best.pt, 3.0MB\n",
      "\n",
      "Validating runs/classify/train2/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.193 🚀 Python-3.11.5 torch-2.1.0+cu121 CUDA:0 (NVIDIA GeForce GTX 1060 6GB, 6070MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1437442 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/train... found 1281 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/val... found 323 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test... found 107 images in 2 classes ✅ \n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 27.31it/s]\n",
      "                   all      0.898          1\n",
      "Speed: 0.1ms preprocess, 1.0ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/train2\u001b[0m\n",
      "Results saved to \u001b[1mruns/classify/train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model_path = \"yolov8n-cls.pt\"\n",
    "data_path = \"Datasets/Classification\"\n",
    "\n",
    "model = YOLO(model_path)  # load model \n",
    "\n",
    "# Train the model\n",
    "valid_results = model.train(\n",
    "   data=data_path, epochs=30, imgsz=224\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.193 🚀 Python-3.11.5 torch-2.1.0+cu121 CUDA:0 (NVIDIA GeForce GTX 1060 6GB, 6070MiB)\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/train... found 1281 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val... found 107 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val... 107 images, 0 corrupt: 100%|██████████| 107/107 [00:00<00:00, 5199.09it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val.cache\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:00<00:00, 21.46it/s]\n",
      "                   all      0.916          1\n",
      "Speed: 0.5ms preprocess, 1.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/val5\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7fb386ecf690>\n",
       "fitness: 0.9579438865184784\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9158878326416016, 'metrics/accuracy_top5': 0.9999999403953552, 'fitness': 0.9579438865184784}\n",
       "save_dir: PosixPath('runs/classify/val5')\n",
       "speed: {'preprocess': 0.4561125675094462, 'inference': 1.392475912504107, 'loss': 0.0008600894535813376, 'postprocess': 0.0008779151417384638}\n",
       "top1: 0.9158878326416016\n",
       "top5: 0.9999999403953552"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.val(data=\"Datasets/Classification/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/10 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/crow_traps/100631_2_1.jpeg: 224x224 crow_traps 0.75, background 0.25, 3.0ms\n",
      "image 2/10 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/crow_traps/101343_2_1.jpeg: 224x224 crow_traps 0.99, background 0.01, 4.6ms\n",
      "image 3/10 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/crow_traps/101550_2_1.jpeg: 224x224 background 1.00, crow_traps 0.00, 3.1ms\n",
      "image 4/10 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/crow_traps/101569_2_1.jpeg: 224x224 background 0.99, crow_traps 0.01, 2.8ms\n",
      "image 5/10 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/crow_traps/103138_2_1.jpeg: 224x224 crow_traps 1.00, background 0.00, 2.9ms\n",
      "image 6/10 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/crow_traps/103519_2_1.jpeg: 224x224 crow_traps 1.00, background 0.00, 3.0ms\n",
      "image 7/10 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/crow_traps/103849_2_1.jpeg: 224x224 crow_traps 1.00, background 0.00, 2.7ms\n",
      "image 8/10 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/crow_traps/104201_2_1.jpeg: 224x224 background 0.99, crow_traps 0.01, 2.7ms\n",
      "image 9/10 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/crow_traps/104270_2_1.jpeg: 224x224 crow_traps 0.51, background 0.49, 2.8ms\n",
      "image 10/10 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/crow_traps/99245_1_0.jpeg: 224x224 crow_traps 0.72, background 0.28, 4.0ms\n",
      "Speed: 2.1ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns/classify/predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(source=\"Datasets/Classification/test/val/crow_traps/\", save=True, imgsz=224, conf=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/100331_0_2.jpeg: 224x224 background 0.90, crow_traps 0.10, 3.2ms\n",
      "image 2/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/100331_1_1.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.8ms\n",
      "image 3/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/100331_2_0.jpeg: 224x224 background 0.99, crow_traps 0.01, 2.8ms\n",
      "image 4/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/100331_2_2.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.9ms\n",
      "image 5/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/100331_3_1.jpeg: 224x224 background 0.99, crow_traps 0.01, 2.7ms\n",
      "image 6/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/100459_1_0.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.9ms\n",
      "image 7/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/100459_1_1.jpeg: 224x224 background 1.00, crow_traps 0.00, 3.7ms\n",
      "image 8/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/100459_1_2.jpeg: 224x224 background 0.94, crow_traps 0.06, 3.8ms\n",
      "image 9/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/100459_2_0.jpeg: 224x224 background 0.99, crow_traps 0.01, 4.1ms\n",
      "image 10/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/100563_0_0.jpeg: 224x224 crow_traps 0.99, background 0.01, 3.1ms\n",
      "image 11/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/100615_0_2.jpeg: 224x224 background 0.98, crow_traps 0.02, 3.2ms\n",
      "image 12/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/100615_2_0.jpeg: 224x224 background 0.99, crow_traps 0.01, 3.4ms\n",
      "image 13/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/100615_3_1.jpeg: 224x224 background 0.77, crow_traps 0.23, 2.7ms\n",
      "image 14/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/100615_3_2.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.8ms\n",
      "image 15/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/100631_2_0.jpeg: 224x224 background 0.99, crow_traps 0.01, 2.7ms\n",
      "image 16/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/100980_0_1.jpeg: 224x224 background 1.00, crow_traps 0.00, 3.4ms\n",
      "image 17/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/100980_2_2.jpeg: 224x224 background 0.96, crow_traps 0.04, 3.2ms\n",
      "image 18/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/100980_3_0.jpeg: 224x224 background 0.99, crow_traps 0.01, 2.8ms\n",
      "image 19/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101123_0_0.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.9ms\n",
      "image 20/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101123_1_0.jpeg: 224x224 background 0.99, crow_traps 0.01, 2.7ms\n",
      "image 21/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101123_3_2.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.8ms\n",
      "image 22/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101125_0_0.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.7ms\n",
      "image 23/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101125_1_0.jpeg: 224x224 background 0.98, crow_traps 0.02, 2.7ms\n",
      "image 24/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101125_2_0.jpeg: 224x224 background 0.63, crow_traps 0.37, 2.7ms\n",
      "image 25/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101125_3_2.jpeg: 224x224 background 0.79, crow_traps 0.21, 2.9ms\n",
      "image 26/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101339_0_0.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.7ms\n",
      "image 27/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101339_0_1.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.7ms\n",
      "image 28/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101339_1_1.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.8ms\n",
      "image 29/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101339_1_2.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.7ms\n",
      "image 30/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101339_3_0.jpeg: 224x224 background 0.97, crow_traps 0.03, 2.7ms\n",
      "image 31/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101343_0_1.jpeg: 224x224 background 0.97, crow_traps 0.03, 2.8ms\n",
      "image 32/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101343_1_1.jpeg: 224x224 background 0.99, crow_traps 0.01, 2.7ms\n",
      "image 33/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101442_0_0.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.7ms\n",
      "image 34/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101442_3_1.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.8ms\n",
      "image 35/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101509_0_0.jpeg: 224x224 background 0.95, crow_traps 0.05, 2.7ms\n",
      "image 36/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101509_1_0.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.7ms\n",
      "image 37/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101517_0_0.jpeg: 224x224 background 0.93, crow_traps 0.07, 2.8ms\n",
      "image 38/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101517_2_2.jpeg: 224x224 background 0.99, crow_traps 0.01, 2.8ms\n",
      "image 39/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101520_0_0.jpeg: 224x224 background 0.99, crow_traps 0.01, 2.8ms\n",
      "image 40/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101520_1_0.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.7ms\n",
      "image 41/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101520_2_2.jpeg: 224x224 background 0.98, crow_traps 0.02, 2.7ms\n",
      "image 42/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101520_3_1.jpeg: 224x224 background 0.99, crow_traps 0.01, 2.8ms\n",
      "image 43/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101546_1_1.jpeg: 224x224 background 0.99, crow_traps 0.01, 2.7ms\n",
      "image 44/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101546_2_0.jpeg: 224x224 background 0.95, crow_traps 0.05, 2.8ms\n",
      "image 45/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101546_3_1.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.7ms\n",
      "image 46/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101548_0_2.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.8ms\n",
      "image 47/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101548_1_1.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.9ms\n",
      "image 48/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101550_2_0.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.7ms\n",
      "image 49/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101559_0_0.jpeg: 224x224 background 0.99, crow_traps 0.01, 2.7ms\n",
      "image 50/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101559_1_2.jpeg: 224x224 background 0.99, crow_traps 0.01, 3.2ms\n",
      "image 51/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101559_3_1.jpeg: 224x224 background 1.00, crow_traps 0.00, 3.8ms\n",
      "image 52/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101569_0_1.jpeg: 224x224 background 1.00, crow_traps 0.00, 3.1ms\n",
      "image 53/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101569_3_0.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.6ms\n",
      "image 54/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101679_1_0.jpeg: 224x224 background 0.92, crow_traps 0.08, 3.9ms\n",
      "image 55/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/101679_1_2.jpeg: 224x224 background 0.60, crow_traps 0.40, 3.0ms\n",
      "image 56/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/102520_0_2.jpeg: 224x224 crow_traps 0.89, background 0.11, 3.2ms\n",
      "image 57/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/102520_2_2.jpeg: 224x224 background 0.99, crow_traps 0.01, 3.8ms\n",
      "image 58/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/102521_1_2.jpeg: 224x224 background 1.00, crow_traps 0.00, 3.8ms\n",
      "image 59/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/102522_0_0.jpeg: 224x224 background 0.92, crow_traps 0.08, 3.5ms\n",
      "image 60/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/102522_1_0.jpeg: 224x224 background 0.99, crow_traps 0.01, 3.5ms\n",
      "image 61/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/102522_3_2.jpeg: 224x224 crow_traps 0.68, background 0.32, 4.0ms\n",
      "image 62/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/102523_2_0.jpeg: 224x224 crow_traps 0.79, background 0.21, 3.6ms\n",
      "image 63/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/102523_3_0.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.8ms\n",
      "image 64/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/102563_1_1.jpeg: 224x224 background 0.98, crow_traps 0.02, 2.7ms\n",
      "image 65/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/102598_0_1.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.7ms\n",
      "image 66/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/102598_1_1.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.8ms\n",
      "image 67/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/102598_2_0.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.7ms\n",
      "image 68/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/102598_3_2.jpeg: 224x224 background 0.93, crow_traps 0.07, 2.7ms\n",
      "image 69/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/102601_0_0.jpeg: 224x224 background 0.61, crow_traps 0.39, 2.7ms\n",
      "image 70/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/102601_1_2.jpeg: 224x224 background 0.97, crow_traps 0.03, 2.8ms\n",
      "image 71/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/103138_1_2.jpeg: 224x224 crow_traps 0.90, background 0.10, 2.8ms\n",
      "image 72/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/103303_3_1.jpeg: 224x224 background 0.99, crow_traps 0.01, 2.7ms\n",
      "image 73/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/103439_0_0.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.7ms\n",
      "image 74/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/103439_1_2.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.8ms\n",
      "image 75/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/103439_2_0.jpeg: 224x224 background 0.99, crow_traps 0.01, 2.7ms\n",
      "image 76/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/103439_3_1.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.6ms\n",
      "image 77/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/103519_3_1.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.7ms\n",
      "image 78/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/103638_3_2.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.7ms\n",
      "image 79/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/103710_1_2.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.7ms\n",
      "image 80/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/103849_0_0.jpeg: 224x224 background 0.68, crow_traps 0.32, 2.7ms\n",
      "image 81/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/103849_0_1.jpeg: 224x224 crow_traps 0.99, background 0.01, 3.5ms\n",
      "image 82/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/103849_0_2.jpeg: 224x224 background 0.55, crow_traps 0.45, 2.7ms\n",
      "image 83/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/103849_3_1.jpeg: 224x224 background 1.00, crow_traps 0.00, 3.3ms\n",
      "image 84/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/104009_0_0.jpeg: 224x224 background 0.76, crow_traps 0.24, 2.9ms\n",
      "image 85/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/104009_1_0.jpeg: 224x224 background 0.58, crow_traps 0.42, 2.7ms\n",
      "image 86/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/104027_0_0.jpeg: 224x224 background 0.55, crow_traps 0.45, 2.7ms\n",
      "image 87/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/104201_3_1.jpeg: 224x224 background 1.00, crow_traps 0.00, 3.0ms\n",
      "image 88/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/104201_3_2.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.6ms\n",
      "image 89/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/104269_0_2.jpeg: 224x224 background 0.96, crow_traps 0.04, 2.8ms\n",
      "image 90/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/104269_1_1.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.7ms\n",
      "image 91/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/104270_2_0.jpeg: 224x224 background 0.98, crow_traps 0.02, 2.6ms\n",
      "image 92/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/104272_2_2.jpeg: 224x224 background 1.00, crow_traps 0.00, 2.8ms\n",
      "image 93/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/104357_0_1.jpeg: 224x224 background 0.95, crow_traps 0.05, 2.6ms\n",
      "image 94/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/104357_1_0.jpeg: 224x224 background 0.99, crow_traps 0.01, 2.8ms\n",
      "image 95/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/104357_1_1.jpeg: 224x224 background 0.94, crow_traps 0.06, 2.6ms\n",
      "image 96/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/104357_1_2.jpeg: 224x224 background 0.95, crow_traps 0.05, 3.1ms\n",
      "image 97/97 /home/davide/Desktop/Projects/RSPB-Crow-traps-detection/Datasets/Classification/test/val/background/104357_3_0.jpeg: 224x224 background 0.98, crow_traps 0.02, 2.3ms\n",
      "Speed: 1.2ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns/classify/predict3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(source=\"Datasets/Classification/test/val/background/\", save=True, imgsz=224, conf=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rspb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
