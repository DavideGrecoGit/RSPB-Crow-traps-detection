{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from patchify import patchify\n",
    "import tifffile as tiff\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "from math import floor\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from utils import make_patches, make_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train data into train-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_split(\"crow_trap\", dataset_dir=\"Datasets/Crow_detection/train\", split_p=0.2)\n",
    "make_split(\"background\", dataset_dir=\"Datasets/Crow_detection/train\", split_p=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train split can be used to generate augmented data and reduce imbalance in the dataset.\n",
    "\n",
    "- **crow_trap generation**: traps are manually masked out and then placed into background images\n",
    "- **general augmentation**: background/crow_trap images can be transformed and distorted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crow trap generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO annotation format (https://medium.com/analytics-vidhya/getting-data-annotation-format-right-for-object-detection-tasks-f41b07eebbf5)\n",
    "<class> <x> <y> <width> <height> \n",
    "ex: 0 0.25 0.44 0.5 0.8\n",
    "class is the object class, (x,y) are centre coordinates of the bounding box. width, height represent width and height of the bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_img(img_filename, center=None, trap_size=None, img_size=(224,224), class_name=\"0\"):\n",
    "    name = img_filename.split(\".\")[0]\n",
    "    f= open(name+\".txt\",\"w+\")\n",
    "\n",
    "    if center and trap_size:\n",
    "        dw = 1. / img_size[0]\n",
    "        dh = 1. / img_size[1]\n",
    "        x = center[0] * dw\n",
    "        y = center[1] * dh\n",
    "        w = trap_size[0] * dw\n",
    "        h = trap_size[1] * dh\n",
    "\n",
    "        annotation = \" \".join([class_name, str(x), str(y), str(h), str(w)])\n",
    "        f.write(annotation)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "annotate_img(\"Datasets/Crow_detection/generated_traps/test_ann.jpg\", (81, 118), (17, 17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_detection_trap_samples(back_dir, trap_dir, save_img_dir, save_ann_dir, save_gt_dir, split_p = 1):\n",
    "\n",
    "    if not os.path.exists(save_img_dir):\n",
    "        os.makedirs(save_img_dir)\n",
    "\n",
    "    if not os.path.exists(save_ann_dir):\n",
    "        os.makedirs(save_ann_dir)\n",
    "\n",
    "    if not os.path.exists(save_gt_dir):\n",
    "        os.makedirs(save_gt_dir)\n",
    "\n",
    "\n",
    "    transform_p = 0.5\n",
    "\n",
    "    combined_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.ColorJitter(\n",
    "                brightness=0.5, contrast=0.15, saturation=0.3, hue=0.3\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    back_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(transform_p),\n",
    "            transforms.RandomVerticalFlip(transform_p),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    test_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(transform_p),\n",
    "            transforms.RandomVerticalFlip(transform_p),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    samples_back = os.listdir(back_dir)\n",
    "    if split_p<1:\n",
    "        _, samples_back = train_test_split(os.listdir(back_dir), test_size=split_p, random_state=42)\n",
    "    print(\"N samples: \",len(samples_back))\n",
    "\n",
    "    samples_trap = os.listdir(trap_dir)\n",
    "\n",
    "    for sample in samples_back:\n",
    "        # Load and transform background and trap images\n",
    "        back = Image.open(os.path.join(back_dir, sample))\n",
    "        back = back_transforms(back)\n",
    "\n",
    "        sample_trap = random.choice(samples_trap)\n",
    "        trap = Image.open(os.path.join(trap_dir, sample_trap))\n",
    "\n",
    "        angle = random.randint(0,360)\n",
    "        trap.rotate(angle, resample=Image.BICUBIC, expand=True)\n",
    "        trap = test_transforms(trap)\n",
    "\n",
    "        # Calculate trap coordinates (top,left) and center\n",
    "        w, h = trap.size\n",
    "        left = random.randint(0, back.size[0]-w)\n",
    "        top = random.randint(0, back.size[1]-h)\n",
    "        center = (left+int(w/2), top+int(h/2))\n",
    "\n",
    "        # Combine and save background + trap\n",
    "        back.paste(trap, (left, top), trap)\n",
    "        back = combined_transforms(back)\n",
    "\n",
    "        new_trap_name = sample.split(\".\")[0] + \"_\" + sample_trap\n",
    "        print(new_trap_name)\n",
    "        annotate_img(os.path.join(save_ann_dir,new_trap_name), center, (w, h), back.size, \"0\")\n",
    "        back.save(os.path.join(save_img_dir,new_trap_name))\n",
    "\n",
    "        # Save GT BB\n",
    "        img_draw = ImageDraw.Draw(back)\n",
    "        img_draw.rectangle(((left, top),(left+w, top+h)), outline='Red')\n",
    "        back.save(os.path.join(save_gt_dir,new_trap_name.split(\".\")[0]+\"_GT.jpeg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N samples:  307\n",
      "101343_3_1_11.png\n",
      "100459_3_0_17.png\n",
      "103638_1_1_3.png\n",
      "101517_0_2_11.png\n",
      "101339_2_0_5.png\n",
      "101546_1_0_4.png\n",
      "100615_3_0_11.png\n",
      "104008_3_0_2.png\n",
      "100980_1_0_17.png\n",
      "101123_2_2_5.png\n",
      "103519_0_2_9.png\n",
      "100615_0_1_15.png\n",
      "101679_0_1_5.png\n",
      "101520_0_1_16.png\n",
      "101343_0_2_18.png\n",
      "101569_2_2_9.png\n",
      "104269_1_0_9.png\n",
      "101442_3_0_13.png\n",
      "101339_2_2_2.png\n",
      "101125_0_1_9.png\n",
      "103303_1_0_13.png\n",
      "102237_0_2_7.png\n",
      "99911_0_2_15.png\n",
      "102563_0_0_10.png\n",
      "101517_3_2_7.png\n",
      "100459_0_0_10.png\n",
      "103519_2_2_3.png\n",
      "101509_1_2_12.png\n",
      "102522_3_1_12.png\n",
      "102521_3_2_18.png\n",
      "104027_1_0_17.png\n",
      "100331_1_0_2.png\n",
      "102523_1_2_17.png\n",
      "100331_1_2_10.png\n",
      "104268_0_2_3.png\n",
      "102598_3_0_14.png\n",
      "101164_1_0_16.png\n",
      "101509_0_2_15.png\n",
      "99911_3_2_10.png\n",
      "102563_3_2_14.png\n",
      "102237_0_1_6.png\n",
      "102563_3_0_7.png\n",
      "101569_3_1_15.png\n",
      "101517_3_1_8.png\n",
      "100631_1_1_5.png\n",
      "102521_0_0_2.png\n",
      "101548_1_2_1.png\n",
      "102601_1_1_1.png\n",
      "102237_3_1_10.png\n",
      "103303_3_2_6.png\n",
      "100331_3_0_13.png\n",
      "101550_0_1_13.png\n",
      "103303_3_0_15.png\n",
      "99495_0_2_17.png\n",
      "102521_0_2_18.png\n",
      "104008_0_1_1.png\n",
      "99495_3_1_10.png\n",
      "104272_3_2_6.png\n",
      "103638_3_1_8.png\n",
      "102523_0_2_5.png\n",
      "101517_0_1_14.png\n",
      "101569_0_0_4.png\n",
      "100459_3_1_13.png\n",
      "102523_0_0_16.png\n",
      "103519_3_0_10.png\n",
      "104201_3_0_12.png\n",
      "101123_0_1_17.png\n",
      "101125_3_0_8.png\n",
      "102521_3_0_10.png\n",
      "99911_0_1_10.png\n",
      "101520_1_2_1.png\n",
      "99495_3_0_16.png\n",
      "102237_3_0_7.png\n",
      "101546_3_2_13.png\n",
      "103849_3_0_3.png\n",
      "101509_3_1_10.png\n",
      "101339_1_0_2.png\n",
      "101509_1_1_8.png\n",
      "104270_2_2_17.png\n",
      "101125_3_1_17.png\n",
      "101517_1_2_16.png\n",
      "104008_1_1_5.png\n",
      "104268_0_1_1.png\n",
      "101339_3_2_15.png\n",
      "103519_1_1_9.png\n",
      "99911_1_0_6.png\n",
      "100980_3_1_3.png\n",
      "104268_1_1_4.png\n",
      "101550_2_2_9.png\n",
      "102521_2_2_1.png\n",
      "100331_3_2_6.png\n",
      "100980_3_2_13.png\n",
      "100459_0_1_8.png\n",
      "101123_2_0_5.png\n",
      "99245_1_0_14.png\n",
      "102237_1_1_2.png\n",
      "103439_1_0_6.png\n",
      "100615_0_0_4.png\n",
      "104272_1_1_4.png\n",
      "102598_1_2_2.png\n",
      "99911_2_0_8.png\n",
      "101442_1_0_4.png\n",
      "99911_3_0_8.png\n",
      "104201_2_2_8.png\n",
      "101442_1_1_12.png\n",
      "104272_0_0_11.png\n",
      "104268_0_0_1.png\n",
      "99495_0_0_9.png\n",
      "104268_1_2_15.png\n",
      "101517_1_1_7.png\n",
      "101509_3_0_8.png\n",
      "104272_3_0_1.png\n",
      "103138_1_1_17.png\n",
      "102523_2_2_4.png\n",
      "100331_0_1_9.png\n",
      "101123_3_1_5.png\n",
      "102563_0_2_9.png\n",
      "104268_1_0_3.png\n",
      "104270_0_2_14.png\n",
      "103710_3_2_12.png\n",
      "103519_1_0_1.png\n",
      "104008_1_2_7.png\n",
      "101559_0_2_10.png\n",
      "103710_2_2_11.png\n",
      "103138_0_1_14.png\n",
      "103638_1_2_8.png\n",
      "101548_3_2_11.png\n",
      "104008_0_2_18.png\n",
      "101509_0_1_5.png\n",
      "101546_3_0_11.png\n",
      "104008_1_0_12.png\n",
      "101517_2_0_17.png\n",
      "101546_0_1_9.png\n",
      "104269_0_0_7.png\n",
      "102522_2_2_15.png\n",
      "101548_0_1_1.png\n",
      "103138_0_2_3.png\n",
      "101442_0_2_11.png\n",
      "104272_1_0_15.png\n",
      "104270_3_1_8.png\n",
      "103303_2_0_18.png\n",
      "101125_0_2_13.png\n",
      "103138_3_1_5.png\n",
      "103710_0_0_1.png\n",
      "101548_2_0_9.png\n",
      "101520_1_1_5.png\n",
      "102523_0_1_11.png\n",
      "103849_2_2_8.png\n",
      "102520_0_1_1.png\n",
      "99495_1_1_7.png\n",
      "101548_1_0_4.png\n",
      "100631_0_0_11.png\n",
      "101442_1_2_11.png\n",
      "101679_0_0_10.png\n",
      "104270_1_2_6.png\n",
      "104357_3_1_13.png\n",
      "104357_3_2_11.png\n",
      "100631_2_2_8.png\n",
      "99495_1_2_13.png\n",
      "103710_0_2_9.png\n",
      "99495_0_1_16.png\n",
      "103519_1_2_15.png\n",
      "101343_3_0_16.png\n",
      "103849_2_0_1.png\n",
      "100615_1_2_9.png\n",
      "101550_1_0_16.png\n",
      "103638_3_0_18.png\n",
      "101442_2_0_11.png\n",
      "101509_3_2_16.png\n",
      "101569_1_2_10.png\n",
      "102601_3_2_2.png\n",
      "104008_3_1_14.png\n",
      "101520_3_0_5.png\n",
      "100980_1_1_3.png\n",
      "102521_2_0_13.png\n",
      "102523_1_1_7.png\n",
      "104269_0_1_8.png\n",
      "103519_3_2_1.png\n",
      "102598_0_0_12.png\n",
      "104008_0_0_7.png\n",
      "101548_2_2_18.png\n",
      "101548_0_0_1.png\n",
      "102601_3_1_2.png\n",
      "102520_2_0_15.png\n",
      "101123_0_2_11.png\n",
      "100459_2_2_8.png\n",
      "103710_3_1_2.png\n",
      "101679_2_2_3.png\n",
      "102522_3_0_5.png\n",
      "103638_0_1_16.png\n",
      "103710_1_1_10.png\n",
      "104272_1_2_3.png\n",
      "103849_1_2_5.png\n",
      "102601_3_0_1.png\n",
      "102598_3_1_1.png\n",
      "103638_2_2_16.png\n",
      "99911_1_1_7.png\n",
      "103138_2_2_10.png\n",
      "101548_3_1_11.png\n",
      "101343_2_0_12.png\n",
      "102520_1_0_1.png\n",
      "102598_1_0_16.png\n",
      "104008_2_2_8.png\n",
      "101679_0_2_7.png\n",
      "100631_1_0_3.png\n",
      "99245_0_0_5.png\n",
      "103439_0_1_1.png\n",
      "102598_2_2_8.png\n",
      "101442_2_2_2.png\n",
      "103849_3_2_6.png\n",
      "103303_1_1_12.png\n",
      "102563_2_1_9.png\n",
      "101550_3_1_7.png\n",
      "99911_1_2_14.png\n",
      "103439_2_2_12.png\n",
      "104272_0_2_10.png\n",
      "102601_2_0_6.png\n",
      "104357_0_2_18.png\n",
      "102237_3_2_17.png\n",
      "101550_3_2_9.png\n",
      "101343_0_0_17.png\n",
      "102601_0_2_5.png\n",
      "104269_3_2_16.png\n",
      "101546_2_2_18.png\n",
      "101550_0_2_7.png\n",
      "102520_3_0_5.png\n",
      "103439_0_2_17.png\n",
      "101559_3_0_2.png\n",
      "103710_0_1_1.png\n",
      "104268_2_2_5.png\n",
      "100980_1_2_5.png\n",
      "103519_2_0_17.png\n",
      "101520_3_2_18.png\n",
      "101125_2_2_3.png\n",
      "104269_3_0_10.png\n",
      "104270_3_2_6.png\n",
      "103519_0_1_13.png\n",
      "104201_0_1_4.png\n",
      "103138_1_0_2.png\n",
      "104008_2_0_2.png\n",
      "100331_0_0_14.png\n",
      "103638_0_2_17.png\n",
      "104357_2_0_7.png\n",
      "102521_1_0_7.png\n",
      "101546_1_2_15.png\n",
      "101550_1_1_7.png\n",
      "103303_2_2_18.png\n",
      "104269_2_2_10.png\n",
      "100459_3_2_3.png\n",
      "103849_1_1_18.png\n",
      "102237_0_0_13.png\n",
      "101442_3_2_1.png\n",
      "101569_3_2_11.png\n",
      "104269_2_0_6.png\n",
      "103439_3_0_8.png\n",
      "102521_3_1_8.png\n",
      "101123_1_1_6.png\n",
      "101550_0_0_13.png\n",
      "102520_3_2_2.png\n",
      "101343_3_2_3.png\n",
      "100615_1_0_11.png\n",
      "104201_1_0_2.png\n",
      "103638_0_0_6.png\n",
      "104268_3_0_8.png\n",
      "103303_0_1_8.png\n",
      "101123_3_0_18.png\n",
      "104272_0_1_1.png\n",
      "103138_2_0_9.png\n",
      "101509_2_0_2.png\n",
      "104269_1_2_8.png\n",
      "102520_1_1_14.png\n",
      "100631_3_0_3.png\n",
      "100615_1_1_17.png\n",
      "104201_2_0_1.png\n",
      "101569_1_1_14.png\n",
      "100980_0_0_5.png\n",
      "100631_3_2_17.png\n",
      "103303_0_2_13.png\n",
      "102237_2_0_17.png\n",
      "103710_1_0_16.png\n",
      "104270_0_0_16.png\n",
      "104270_1_0_14.png\n",
      "101546_0_2_9.png\n",
      "102237_1_2_11.png\n",
      "102563_0_1_17.png\n",
      "104268_3_2_4.png\n",
      "101559_3_2_2.png\n",
      "102237_1_0_4.png\n",
      "102601_0_1_13.png\n",
      "104270_3_0_11.png\n",
      "102523_3_1_5.png\n",
      "104201_0_2_15.png\n",
      "101679_3_1_17.png\n",
      "103710_3_0_9.png\n",
      "100980_0_2_13.png\n",
      "102520_1_2_16.png\n",
      "100631_0_2_13.png\n",
      "102520_0_0_3.png\n",
      "104201_0_0_12.png\n",
      "101679_1_1_4.png\n",
      "102563_2_0_7.png\n",
      "100980_2_0_2.png\n",
      "101509_2_2_2.png\n",
      "99495_1_0_14.png\n",
      "101339_3_1_6.png\n",
      "103138_3_0_17.png\n",
      "99495_2_0_13.png\n"
     ]
    }
   ],
   "source": [
    "trap_dir = \"Datasets/backup/Only_traps\"\n",
    "back_dir = \"Datasets/Crow_detection/train/background\"\n",
    "save_img_dir = \"Datasets/Crow_detection_train/images/train\"\n",
    "save_ann_dir = \"Datasets/Crow_detection_train/labels/train\"\n",
    "save_gt_dir = \"Datasets/Crow_detection/train/GT_BB\"\n",
    "\n",
    "generate_detection_trap_samples(back_dir, trap_dir, save_img_dir, save_ann_dir, save_gt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N samples:  77\n",
      "101520_2_0_7.png\n",
      "103138_3_2_10.png\n",
      "102522_0_1_12.png\n",
      "103303_1_2_11.png\n",
      "104268_2_0_18.png\n",
      "104357_0_0_8.png\n",
      "102237_2_2_16.png\n",
      "99495_3_2_12.png\n",
      "100459_0_2_14.png\n",
      "101559_2_2_1.png\n",
      "103303_0_0_11.png\n",
      "101559_2_0_16.png\n",
      "103638_2_0_15.png\n",
      "102601_1_0_2.png\n",
      "101569_1_0_3.png\n",
      "101125_1_1_9.png\n",
      "102563_1_0_16.png\n",
      "102601_2_2_11.png\n",
      "101343_2_2_15.png\n",
      "101520_0_2_17.png\n",
      "104270_0_1_5.png\n",
      "101559_1_0_11.png\n",
      "102522_1_1_1.png\n",
      "102521_0_1_17.png\n",
      "104268_3_1_15.png\n",
      "104270_1_1_8.png\n",
      "100615_2_2_3.png\n",
      "103439_1_1_2.png\n",
      "104357_2_2_5.png\n",
      "102522_2_0_6.png\n",
      "103849_1_0_11.png\n",
      "102522_1_2_8.png\n",
      "100631_1_2_6.png\n",
      "101546_0_0_8.png\n",
      "102521_1_1_5.png\n",
      "103519_0_0_6.png\n",
      "101123_1_2_16.png\n",
      "101343_1_0_2.png\n",
      "99911_0_0_5.png\n",
      "101679_3_2_16.png\n",
      "102520_3_1_17.png\n",
      "101559_1_1_17.png\n",
      "101569_0_2_2.png\n",
      "103710_2_0_7.png\n",
      "101442_0_1_10.png\n",
      "104269_3_1_12.png\n",
      "99911_2_2_17.png\n",
      "102523_1_0_10.png\n",
      "101125_1_2_1.png\n",
      "101343_1_2_7.png\n",
      "103439_3_2_13.png\n",
      "102563_3_1_4.png\n",
      "102522_0_2_17.png\n",
      "101548_3_0_5.png\n",
      "101679_2_0_6.png\n",
      "101550_1_2_15.png\n",
      "101517_3_0_4.png\n",
      "103638_2_1_16.png\n",
      "101164_0_0_16.png\n",
      "102563_1_2_9.png\n",
      "103138_0_0_16.png\n",
      "100631_3_1_3.png\n",
      "101569_2_0_7.png\n",
      "101517_1_0_8.png\n",
      "104272_3_1_1.png\n",
      "104272_2_0_13.png\n",
      "102598_0_2_7.png\n",
      "99911_3_1_4.png\n",
      "101679_3_0_13.png\n",
      "104008_3_2_5.png\n",
      "101339_0_2_2.png\n",
      "101559_0_1_2.png\n",
      "101550_3_0_17.png\n",
      "102523_3_2_16.png\n",
      "104201_1_1_10.png\n",
      "100631_0_1_3.png\n",
      "104201_1_2_11.png\n"
     ]
    }
   ],
   "source": [
    "trap_dir = \"Datasets/backup/Only_traps\"\n",
    "back_dir = \"Datasets/Crow_detection/val/background\"\n",
    "save_img_dir = \"Datasets/Crow_detection_train/images/val\"\n",
    "save_ann_dir = \"Datasets/Crow_detection_train/labels/val\"\n",
    "save_gt_dir = \"Datasets/Crow_detection/val/GT_BB\"\n",
    "\n",
    "generate_detection_trap_samples(back_dir, trap_dir, save_img_dir, save_ann_dir, save_gt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### General augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101343_2_0_aug.jpeg\n",
      "103710_1_0_aug.jpeg\n",
      "103138_1_0_aug.jpeg\n",
      "104357_2_2_aug.jpeg\n",
      "101520_3_0_aug.jpeg\n",
      "102523_3_1_aug.jpeg\n",
      "104008_1_2_aug.jpeg\n",
      "101164_0_0_aug.jpeg\n",
      "102237_1_0_aug.jpeg\n",
      "103710_0_1_aug.jpeg\n",
      "101559_2_0_aug.jpeg\n",
      "99911_3_0_aug.jpeg\n",
      "103138_3_2_aug.jpeg\n",
      "101679_3_1_aug.jpeg\n",
      "104268_1_2_aug.jpeg\n",
      "103439_2_2_aug.jpeg\n",
      "99495_1_2_aug.jpeg\n",
      "104269_1_0_aug.jpeg\n",
      "102237_2_2_aug.jpeg\n",
      "101509_0_2_aug.jpeg\n",
      "100615_1_1_aug.jpeg\n",
      "101550_0_2_aug.jpeg\n",
      "103303_2_0_aug.jpeg\n",
      "99911_1_1_aug.jpeg\n",
      "101343_0_0_aug.jpeg\n",
      "101548_1_2_aug.jpeg\n",
      "104270_0_0_aug.jpeg\n",
      "104268_0_2_aug.jpeg\n",
      "103303_0_2_aug.jpeg\n",
      "101509_3_0_aug.jpeg\n",
      "104269_1_2_aug.jpeg\n",
      "101442_2_2_aug.jpeg\n",
      "100980_1_0_aug.jpeg\n",
      "102522_2_2_aug.jpeg\n",
      "102521_1_0_aug.jpeg\n",
      "101679_0_2_aug.jpeg\n",
      "104268_3_1_aug.jpeg\n",
      "101442_2_2_aug.jpeg\n",
      "102520_1_2_aug.jpeg\n",
      "101517_0_1_aug.jpeg\n",
      "104270_0_0_aug.jpeg\n",
      "100631_3_0_aug.jpeg\n",
      "104272_2_0_aug.jpeg\n",
      "102520_1_0_aug.jpeg\n",
      "103439_0_1_aug.jpeg\n",
      "101125_0_2_aug.jpeg\n",
      "102521_3_0_aug.jpeg\n",
      "100459_0_0_aug.jpeg\n",
      "100631_3_0_aug.jpeg\n",
      "104357_3_2_aug.jpeg\n",
      "103303_1_0_aug.jpeg\n",
      "104201_0_0_aug.jpeg\n",
      "101546_1_2_aug.jpeg\n",
      "102601_0_2_aug.jpeg\n",
      "100980_0_0_aug.jpeg\n",
      "102520_3_2_aug.jpeg\n",
      "102523_1_1_aug.jpeg\n",
      "104270_0_0_aug.jpeg\n",
      "103138_3_1_aug.jpeg\n",
      "101343_0_0_aug.jpeg\n",
      "100631_2_2_aug.jpeg\n",
      "102237_1_2_aug.jpeg\n",
      "104357_2_0_aug.jpeg\n",
      "101123_3_1_aug.jpeg\n",
      "101164_0_0_aug.jpeg\n",
      "101550_2_2_aug.jpeg\n",
      "102601_3_2_aug.jpeg\n",
      "103849_3_0_aug.jpeg\n",
      "103710_0_2_aug.jpeg\n",
      "103519_1_2_aug.jpeg\n",
      "99911_1_2_aug.jpeg\n",
      "101339_3_2_aug.jpeg\n",
      "101125_2_2_aug.jpeg\n",
      "102523_3_1_aug.jpeg\n",
      "102521_0_1_aug.jpeg\n",
      "101509_2_0_aug.jpeg\n",
      "103439_2_2_13_aug.jpeg\n",
      "99495_1_1_7_aug.jpeg\n",
      "101442_1_1_9_aug.jpeg\n",
      "103638_3_0_16_aug.jpeg\n",
      "101517_1_1_13_aug.jpeg\n",
      "102523_1_2_3_aug.jpeg\n",
      "103439_0_1_17_aug.jpeg\n",
      "101520_3_0_15_aug.jpeg\n",
      "102237_3_1_18_aug.jpeg\n",
      "100563_1_0_aug.jpeg\n",
      "102523_1_1_9_aug.jpeg\n",
      "101548_0_0_9_aug.jpeg\n",
      "104357_3_1_8_aug.jpeg\n",
      "101679_0_0_15_aug.jpeg\n",
      "99911_2_0_15_aug.jpeg\n",
      "104268_1_1_18_aug.jpeg\n",
      "99911_1_0_7_aug.jpeg\n",
      "99911_2_0_15_aug.jpeg\n",
      "101343_1_0_5_aug.jpeg\n",
      "101123_3_1_15_aug.jpeg\n",
      "101559_2_2_3_aug.jpeg\n",
      "103638_1_1_5_aug.jpeg\n",
      "104269_0_1_12_aug.jpeg\n",
      "101517_3_1_12_aug.jpeg\n",
      "101123_3_1_15_aug.jpeg\n",
      "102520_2_1_aug.jpeg\n",
      "104269_0_1_12_aug.jpeg\n",
      "103710_0_1_6_aug.jpeg\n",
      "104268_2_0_3_aug.jpeg\n",
      "102237_1_2_11_aug.jpeg\n",
      "103439_0_1_17_aug.jpeg\n",
      "102237_0_2_16_aug.jpeg\n",
      "103519_1_1_7_aug.jpeg\n",
      "100631_3_1_10_aug.jpeg\n",
      "103138_3_0_17_aug.jpeg\n",
      "103638_3_1_12_aug.jpeg\n",
      "104269_3_1_8_aug.jpeg\n",
      "101679_0_1_13_aug.jpeg\n",
      "101550_3_0_2_aug.jpeg\n",
      "104272_3_1_1_aug.jpeg\n",
      "102237_0_0_12_aug.jpeg\n",
      "100331_1_0_1_aug.jpeg\n",
      "100631_0_0_10_aug.jpeg\n",
      "104269_3_1_8_aug.jpeg\n",
      "104272_3_0_6_aug.jpeg\n",
      "99495_0_1_11_aug.jpeg\n",
      "102520_2_0_17_aug.jpeg\n",
      "104269_2_0_7_aug.jpeg\n",
      "102522_0_1_13_aug.jpeg\n",
      "103519_2_2_11_aug.jpeg\n",
      "104201_2_2_9_aug.jpeg\n",
      "102520_1_1_11_aug.jpeg\n",
      "102521_1_1_17_aug.jpeg\n",
      "101343_0_0_11_aug.jpeg\n",
      "102521_3_2_7_aug.jpeg\n",
      "102523_3_1_7_aug.jpeg\n",
      "99495_0_1_11_aug.jpeg\n",
      "99911_2_1_aug.jpeg\n",
      "103303_1_0_1_aug.jpeg\n",
      "101164_1_0_5_aug.jpeg\n",
      "104268_3_2_8_aug.jpeg\n",
      "102521_0_0_1_aug.jpeg\n",
      "103638_2_0_16_aug.jpeg\n",
      "101343_2_2_11_aug.jpeg\n",
      "104269_3_2_5_aug.jpeg\n",
      "100615_2_2_4_aug.jpeg\n",
      "101559_0_2_1_aug.jpeg\n",
      "101559_2_1_aug.jpeg\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms.autoaugment import AutoAugmentPolicy\n",
    "\n",
    "transform_p = 0.8\n",
    "\n",
    "def apply_general_augmentation(samples_dir, save_dir, p_to_generate = 0.65, auto_augment_policy = AutoAugmentPolicy.SVHN, replace=True):\n",
    "\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.RandomVerticalFlip(0.5),\n",
    "            transforms.AutoAugment(auto_augment_policy),\n",
    "            transforms.ColorJitter(\n",
    "                brightness=0.5, contrast=0.15, saturation=0.3, hue=0.3\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    samples_list = random.choices(\n",
    "        os.listdir(samples_dir), k=int(len(os.listdir(samples_dir)) * p_to_generate)\n",
    "    )\n",
    "\n",
    "    for sample in samples_list:\n",
    "\n",
    "        sample_img = Image.open(os.path.join(samples_dir, sample))\n",
    "        sample_img = transform(sample_img)\n",
    "        \n",
    "        sample_name = sample.split(\".\")[0] + \"_aug\" + \".jpeg\"\n",
    "        if replace:\n",
    "            sample_name = sample\n",
    "\n",
    "        print(sample_name)\n",
    "        sample_img.save(os.path.join(save_dir, sample_name))\n",
    "\n",
    "apply_general_augmentation(\"Datasets/Crow_classify/train/background\", \"Datasets/Crow_classify/train/background\", p_to_generate = 0.2, replace=False)\n",
    "apply_general_augmentation(\"Datasets/Crow_classify/train/crow_trap\", \"Datasets/Crow_classify/train/crow_trap\", p_to_generate = 0.2, replace=False)\n",
    "\n",
    "# apply_general_augmentation(\"Datasets/Crow_classify/train/background\", \"Datasets/Crow_classify/train/background\", p_to_generate = 0.2, replace=True)\n",
    "# apply_general_augmentation(\"Datasets/Crow_classify/train/crow_trap\", \"Datasets/Crow_classify/train/crow_trap\", p_to_generate = 0.2, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample list:  406\n",
      "345 61\n",
      "Sample list:  453\n",
      "385 68\n"
     ]
    }
   ],
   "source": [
    "make_split(\"crow_trap\", dataset_dir=\"Datasets/Crow_classify/train\", split_p=.15)\n",
    "make_split(\"background\", dataset_dir=\"Datasets/Crow_classify/train\", split_p=.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_grey(samples_dir, save_dir):\n",
    "\n",
    "    samples_list = os.listdir(samples_dir)\n",
    "\n",
    "    for sample in samples_list:\n",
    "\n",
    "        sample_img = Image.open(os.path.join(samples_dir, sample))\n",
    "        to_greyscale = transforms.Grayscale()\n",
    "        sample_img = to_greyscale(sample_img)\n",
    "        \n",
    "        sample_img.save(os.path.join(save_dir, sample))\n",
    "\n",
    "to_grey(\"Datasets/Crow_classify_grey/train/background\", \"Datasets/Crow_classify_grey/train/background\")\n",
    "to_grey(\"Datasets/Crow_classify_grey/train/crow_trap\", \"Datasets/Crow_classify_grey/train/crow_trap\")\n",
    "\n",
    "to_grey(\"Datasets/Crow_classify_grey/val/background\", \"Datasets/Crow_classify_grey/val/background\")\n",
    "to_grey(\"Datasets/Crow_classify_grey/val/crow_trap\", \"Datasets/Crow_classify_grey/val/crow_trap\")\n",
    "\n",
    "to_grey(\"Datasets/Crow_evaluate_classify_grey/val/background\", \"Datasets/Crow_evaluate_classify_grey/val/background\")\n",
    "to_grey(\"Datasets/Crow_evaluate_classify_grey/val/crow_trap\", \"Datasets/Crow_evaluate_classify_grey/val/crow_trap\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rspb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
